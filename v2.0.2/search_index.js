var documenterSearchIndex = {"docs":
[{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"EditURL = \"../../../examples/Full_processing.jl\"","category":"page"},{"location":"examples/Full_processing.html#Processing-data","page":"Processing data","title":"Processing data","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"In this notebook, we reproduce the typical steps here for processing spectra","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"For this example, we create two Gaussian signals randomly sampled along two different X axis, with noise and increasing backgrounds. One of them will also have a strong spike!","category":"page"},{"location":"examples/Full_processing.html#Signal-creation","page":"Processing data","title":"Signal creation","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"using Spectra, Plots\n\n# we create a fake signal with\nx_1 = rand(1000)*100\nx_2 = rand(1000)*100\n\n# create a signal that is the combination of two gaussian peaks plus a background\nbackground_1 = 0.08 * x_1\nbackground_2 = 0.03 * x_2\n\n# some noise\nnoise_1 = 0.5*randn(1000)\nnoise_2 = 0.3*randn(1000)\n\n# the full toy signals\ny_1 = gaussian(x_1, 10.0, 40., 5.) .+ background_1 .+ noise_1\ny_2 = gaussian(x_2, 20.0, 60., 9.) .+ background_2 .+ noise_2\n\n# one of them will have a spike!\ny_1[600] = 250.0\n\n# make a plot of our two spectra\nscatter(x_1, y_1)\nscatter!(x_2, y_2)","category":"page"},{"location":"examples/Full_processing.html#First-possible-steps","page":"Processing data","title":"First possible steps","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"We can do the following steps (not necessarily in this order):","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"the X values are randomly sorted, we can solve that using flipsp\nWe may like to get our spectra on the same X axis for convenience using resample\nSpikes are present: we can remove them using despiking\nBackgrounds are present: we can remove them using baseline\nSignals are noisy: we can smooth them using smooth\nWe can correct for temperature and laser wavelength using tlcorrection\nWe can normalize the spectra using normalise\nWe can fit the peaks using fit_peaks","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"Let's do it!","category":"page"},{"location":"examples/Full_processing.html#Sort-X-Axis","page":"Processing data","title":"Sort X Axis","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"We can sort the data by passing an array of spectra. After that we should have not problem plotting things with lines for instance!","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"spectrum_1 = flipsp([x_1 y_1])\nspectrum_2 = flipsp([x_2 y_2])\nplot(spectrum_1[:,1], spectrum_1[:, 2])\nplot!(spectrum_2[:,1], spectrum_2[:, 2])\nsavefig(\"fp_1.svg\"); nothing #hide","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"(Image: )","category":"page"},{"location":"examples/Full_processing.html#Remove-spikes","page":"Processing data","title":"Remove spikes","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"OK, the plot above reveals a strong spike in one of the signals. We will treat actually both signals with despiking to remove possible spikes from the signals, using the default parameters. In summary, with the default settings, despiking checks if any points in a spectrum differ by more than 3 sigma from the mean value of the 4 neighboring points. You can change the default values to adjust the threshold (for more or less than 3-sigma), or to modify the number of neighboring points considered.","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"y_1 = despiking(x_1, y_1)\ny_2 = despiking(x_2, y_2)","category":"page"},{"location":"examples/Full_processing.html#Resample-to-have-everything-on-the-same-X-axis","page":"Processing data","title":"Resample to have everything on the same X axis","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"Using resample, we get everything on the same X axis. As we have two spectra with two different X axis, we simply provide them in a Vector like this:","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"x_new = collect(0.:0.5:100)\nspectra_ = [[x_1 y_1], [x_2 y_2]]\nspectra_same_x = resample(spectra_, x_new)\nplot(x_new, spectra_same_x)\nsavefig(\"fp_2.svg\"); nothing #hide","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"(Image: )","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"We see tiny problems with the interpolation, we can solve them using another method from DataInterpolations.jl, such as Linear:","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"spectra_same_x = resample(spectra_, x_new, method=\"LinearInterpolation\")\nplot(x_new, spectra_same_x)\nsavefig(\"fp_3.svg\"); nothing #hide","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"(Image: )","category":"page"},{"location":"examples/Full_processing.html#Remove-a-background","page":"Processing data","title":"Remove a background","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"Now we can remove a background using the baseline function. Similarly to the other functions, you can pass x and y vectors or a x vectors and an array of y spectra. We will do that here:","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"ys_corrected, ys_baselines = baseline(x_new, spectra_same_x, method=\"arPLS\")\np1 = plot(x_new, spectra_same_x)\nplot!(x_new, ys_baselines, labels=[\"background 1\" \"background 2\"])\nsavefig(\"fp_4.svg\"); nothing #hide","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"(Image: )","category":"page"},{"location":"examples/Full_processing.html#Measure-peak-parameters","page":"Processing data","title":"Measure peak parameters","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"We can now measure the parameters of each peak, for instance their centroid:","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"println(\"Centroids are:\")\nprintln(centroid(x_new, ys_corrected))","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"The peakmeas function to get access to a bunch of parameters: intensity, position, hwhm, centroïd","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"println(\"intensity, position, hwhm, centroïd are:\")\nprintln(peakmeas(x_new, ys_corrected[:,1]))","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"If multiple peaks with a background are present, the best is to use the findpeaks() function It can even make a nice plot. Beware that you may have to tweak the windowsize, minwidth, minheight to detect only the main peaks... See the documentation of find_peaks for details. for more precise usage, also see the Peaks.jl package.","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"result = find_peaks(x_new, ys_corrected[:,1], window_size=1, min_width=2., min_height=2.0, smoothing=true)\nprintln(\"Peak positions: \", result.peak_positions)\nprintln(\"Peak heights: \", result.peak_heights)\nprintln(\"Peak HWHMs: \", result.peak_hwhms)\nprintln(\"Peak centroids: \", result.peak_centroids)\nresult.plot_peaks","category":"page"},{"location":"examples/Full_processing.html#Peak-fitting!","page":"Processing data","title":"Peak fitting!","text":"","category":"section"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"We can retrieve the parameters of the two peaks using peak fitting too! We do a quick fit with very loose prior uncertainties on the peak parameters, and unrestrictive lowerbounds and upperbounds. Those informations are provided in a vector of tuples, one tuple per peak: (type, initialparams, prior uncertainties, lowerbounds, upper_bounds)","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"peaks_info = [\n        (:gaussian, [10.5, 50.0, 5.0], [100.0, 100.0, 100.0], [0., 0., 0.], [Inf, Inf, Inf]),\n    ]","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"we declare the context and fit the signals","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"ctx_1 = prepare_context(x_new, ys_corrected[:,1], peaks_info)\nctx_2 = prepare_context(x_new, ys_corrected[:,2], peaks_info)\nresult_1 = fit_peaks(ctx_1, backend=:Optim)\nresult_2 = fit_peaks(ctx_2, backend=:Optim)\n\nprintln(\"Parameters and fit for the first signal:\")\nprint_params(result_1.peak_results)\nplot_fit(ctx_1, result_1.peak_results)\nsavefig(\"fp_5.svg\"); nothing #hide","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"(Image: )","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"println(\"Parameters and fit for the second signal:\")\nprint_params(result_2.peak_results)\nplot_fit(ctx_2, result_2.peak_results)\nsavefig(\"fp_6.svg\"); nothing #hide","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"(Image: )","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"","category":"page"},{"location":"examples/Full_processing.html","page":"Processing data","title":"Processing data","text":"This page was generated using Literate.jl.","category":"page"},{"location":"PeakFitting.html#Peak-fitting","page":"Peak fitting","title":"Peak fitting","text":"","category":"section"},{"location":"PeakFitting.html#Introduction","page":"Peak fitting","title":"Introduction","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"Spectra allows to fit a spectrum with a sum of peaks, of different shapes. For that, we rely on the peak shape functions gaussian, lorentzian, pseudovoigt and pearson7. Using those, you can generate a signal given x, and peak parameters. To generate a signal composed of multiple contributions from different peaks, use the create_peaks function. It is a useful function for instance to create \"fake\" signals and test our peak fitting function, fit_peaks. ","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"fit_peaks uses either Optim.jl or a custom quasi-Newton algorithm to fit the sum of the peaks y_calc to an observed signal y affected by errors sigma_y. The regression also takes into account à priori errors sigma_m_prior on prior model parameters m_prior: we assume a Gaussian prior on model parameters with a mean m_prior and a covariance matrix C_M which diagonal contains sigma_m_prior^2.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"Given the forward calculation of y_calc as","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"y_calc = g(m)","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"with m the model parameters and g the forward model, the misfit function S is (Tarantola 2005, chapter 3, eq. 3.46):","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"S(m) = frac12(y - y_calc)^t C_D^-1(y - y_calc) + (m - m_prior)^tC_M^-1(m-m_prior)","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"where C_D^-1 is the inverse of the data covariance matrix, which diagonal contains sigma_y^2. The misfit function is related to the posterior probability density in the model space following K exp (-S(m)), with K a constant. Here, we are dealing with a non-linear problem so this posterior probability density is not Gaussian. However, we assume that it can be linearized near m_prior. Therefore, starting close to or at m_prior, we can use the following quasi-Newton algorithm to find a suitable solution (Tarantola 2005, eq. 3.51):","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"m_n+1 = m_n - mu_n(G_n^tC_D^-1G_n + C_M^-1)^-1(G_n^tC_D^-1(y_calc n - y) + C_M^-1(m_n - m_prior))","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"where y_calc n is the model output at iteration n with the set of parameters m_n, (G_n)^i_alpha = (fracg^im^alpha)_m_n is the matrix of partial derivatives, and mu_n a step size typically lower or equal to 1. In fit_peaks, the two parameters maxiter and relax control the maximum number of iterations n and the step size mu_n, with mu_n = frac1textrelax.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"The other available method is the Interior Point Newton algorithm from Optim.jl (:Optim backend). This method implements an interior-point primal-dual Newton algorithm for solving the nonlinear, constrained optimization problem. In other terms, it allows the use of constraints, such as parameter boundaries. This is the main difference with the quasi-Newton method. The misfit function that is minimized is the S(m) function provided above.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"Convergence between the two methods usually is similar, with the quasi-Newton method being slightly faster. However, as there is no boundaries on parameters, one may have problems for instance if the intensity of one peak is close to 0. The quasi-Newton method offers no boundaries for the parameter values, contrary to the Interior Point Newton method. ","category":"page"},{"location":"PeakFitting.html#Fitting-procedure","page":"Peak fitting","title":"Fitting procedure","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"A short example probably is better than many worlds. We are going to fit a synthetic signal that we created ourselves with the following code:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"using Plots\nusing Spectra\nusing Statistics\n\n# The X axis\nx = collect(0:0.2:100)\n\n# The \"perfect\" Y signal\ny_perfect = (\n    gaussian(x, [10.0, 35.0, 10.0]) +\n    lorentzian(x, [15.0, 55.0, 3.0]) +\n    pearson7(x, [20.0, 45.0, 2.0, 0.4])\n)\n# Of course, in real world we have noise, here it is Gaussian\nnoise = randn(length(x))*0.3\n\n# This is what we observe and want to fit\ny_obs = y_perfect + noise\n\n# Let's visualize it!\np1 = plot(x, [y_perfect, y_obs]; labels=[\"The true signal\" \"Observations\"])\nsavefig(\"fit_1.svg\"); nothing #hide","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"(Image: )","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"First, you define a vector containing named vectors of peak types, m_prior, sigma_m_prior, and lower and upper boundaries. For instance, after a visual review of the signal above, you would declare a vector of peak informations like this:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"# (peak_type, m_prior, sigma_m_prior, lower_bounds, upper_bounds)\npeaks_info = [\n    (   \n        :gaussian, # peak_type\n        [10.5, 30.0, 11.0], # m_prior (intensity, position, hwhm)\n        [5.0, 5.0, 3.0], # sigma_m_prior\n        [0.0, 0.0, 0.0], # lower_bounds\n        [Inf, Inf, 50.0]), # upper_bounds\n    (\n        :lorentzian, # peak_type\n        [17.5, 54.0, 3.1], # m_prior (intensity, position, hwhm)\n        [5.0, 3.0, 1.0], # sigma_m_prior\n        [0.0, 0.0, 0.0], # lower_bounds\n        [Inf, Inf, Inf], # upper_bounds\n    ),\n    (\n        :pearson7, # peak_type\n        [21.5, 44.0, 3.0, 0.4], # m_prior (intensity, position, hwhm, shape exponent)\n        [3.0, 2.0, 5.0, 0.02], # sigma_m_prior\n        [0.0, 0.0, 0.0, 0.0], # lower_bounds\n        [100.0, 100.0, 50.0, Inf], # upper_bounds\n    ),\n]","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"note: Note\nUpper and lower boundaries for model parameters are always required when constructing this peaks information vector. However, remember that they are not used in the quasi-Newton method.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"We then pass the data and this vector of peak informations to prepare_context that stores everything in a Julia object. In addition to peaks_info, you will need the data vectors x, y_obs, and the errors on y_obs. Usually we do not have a precise idea of those errors. A good approximation can be provided by the difference between the observed signal and a smoothed version. We adopt this approach here and check if the estimated error makes sens:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"y_smo = smooth(x, y_obs, method=\"gcvspline\");\nestimated_mean_error = sqrt(mean((y_obs .- y_smo).^2))\nprintln(\"The estimated mean standard error on y_obs is $(round(estimated_mean_error,digits=2))\")","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"OK, the result seems to be not too bad. We will place ourselves in a \"real world\" situation and  use those errors. For convenience we create an vector of errors","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"estimated_error = estimated_mean_error * ones(size(x));","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"We can now pass the data and associated errors to prepare_context: ","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"ctx = prepare_context(x, y_obs, peaks_info, estimated_error)","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"note: Note\nestimated_error is an positional argument that will be set to an array of 1 if you do not pass a vector. It is advised to pass proper errors for a proper scaling of the misfit function.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"From there, a good thing is to check that your prior model is not too remote from a good fit. The algorithms we use are local optimization methods and do not aim at finding a global minimum, but only local solutions. If you set m_prior to values far from the solution, they will fail. To check your starting parameters, we can fit the prior model and the data using:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"p = plot_fit(ctx, title=\"Prior model\")\nsavefig(\"fit_2.svg\"); nothing #hide","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"(Image: )","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"Modify your starting parameters until the model starts to make sense, and then perform a fit calling fit_peaks with your favorite backend. For instance, if you want to use IPNewton, call:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"result = fit_peaks(ctx, backend=:Optim)","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"or if you want to use the quasi-Newton method described above, call:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"result = fit_peaks(ctx, backend=:qGN, maxiter=100, relax=5)","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"result is an object containing:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"context::FitContext: Fit context\npeak_results::Vector: Peak results\nparams::Vector{Float64}: Peak parameters with uncertainties\ncovariance::Matrix{Float64}: Covariance matrix\nerrors::Vector{Float64}: 1-sigma standard errors on parameters\ny_calc::Vector{Float64}: Model predictions\nresiduals::Vector{Float64}: Residuals","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"In result.peal_results, numbers are now Measurements as we use the Measurements.jl library to automatically propagate fitting errors for peak area calculations. ","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"After a fit, you can print the parameters and peak areas using print_params and plot the fit using plot_fit. Let's do the fit and those steps below","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"result = fit_peaks(ctx, backend=:Optim, maxiter=100, relax=10) # hide\nprint_params(result.peak_results)\n\nplot_fit(ctx, result.peak_results)\nsavefig(\"fit_3.svg\"); nothing #hide","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"(Image: )","category":"page"},{"location":"PeakFitting.html#Errors-on-peak-parameters","page":"Peak fitting","title":"Errors on peak parameters","text":"","category":"section"},{"location":"PeakFitting.html#Errors-provided-by-fit_peaks","page":"Peak fitting","title":"Errors provided by fit_peaks","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"The errors provided by fit_peaks come from the evaluation of the Hessian matrix at the optimal point. In the quasi-Newton algorithm, we directly calculate the posterior model covariance matrix as (Tarantola, 2005, eq. 3.53):","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"C_M post = C_M - C_MG^t(G C_M Gt +C_D)^-1G C_M","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"and retrieve the standard errors on model parameters from the squared root of the diagonal of C_M post. In the IPNewton case, we use ForwardDiff.hessian() to calculate the Hessian matrix at the optimal point to optain C_M post.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"note: Note\nDo not neglect off-diagonal terms in C_M post. Peak parameters often are strongly correlated, and neglecting off-diagonal terms may lead to report wrong errors on quantities that depends on several peak parameters, such as peak areas. This is why we automatically propagate errors using C_M post and Measurements.jl when calculating peak areas in fit_peaks for instance.","category":"page"},{"location":"PeakFitting.html#Checking-errors-with-bootstrapping","page":"Peak fitting","title":"Checking errors with bootstrapping","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"C_M post may not necessarily contain valid parameter uncertainties, particularly if the problem is strongly non-linear.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"To check for parameter errors, one option is to use bootstrapping. bootstrap allows us to bootstrap a spectrum and refit the model on the spectrum subsamples. You will obtain samples of models all adjusted on slightly different data. Using the model samples, we can check that the errors calculated from the Hessian are valid, or if they are not, we can use the new errors calculated from the bootstrap samples.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"The interface is easy, similar to that of fit_peaks but the fit context is defined internally so  you don't even have to worry about that. For instance, using the quasi-Newton method, we can do: ","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"boot_params, boot_results = bootstrap(x, y_obs, estimated_error, peaks_info, nb_boot = 50, backend=:Optim);\nnothing # hide","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"tip: Tip\nThe quasi-Newton algorithm is the quickest so you may prefer this one for bootstrapping. If so, you can try also setting maxiter to a value as small as possible without affecting fit convergence. Another tip is to provide a new peaks_info vector with m_prior set to the values of a good fit that you previously did.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"tip: Tip\nHere we only used 50 bootstraps for the sake of generating the documentation in a reasonable time. In practice, you should use more bootstraps (e.g. 1000) to get a good estimate of the errors.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"The bootstrap function returns:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"a matrix of size (nb_params, nb_boot) with the fitted parameters (here boot_params);\na peakresults objects with values tied to their errors thanks to Measurements.jl (here called `bootresults`).","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"We can now print the bootstrapped results and compare the errors with those previously calculated from the Hessian:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"print_params(boot_results)","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"OK, actually for this example, we see that the errors from the boostrap analysis are close to those calculated from the Hessian matrix. Everything thus seems OK.","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"Of course, a final quick visual inspection is always nice. This can be done by passing the  median of the matrix of bootstrapped parameters to the plot_fit function:","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"plot_fit(ctx, boot_results)\nsavefig(\"fit_4.svg\"); nothing #hide","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"(Image: )","category":"page"},{"location":"PeakFitting.html#Bayesian-MCMC-fit-with-Turing.jl","page":"Peak fitting","title":"Bayesian MCMC fit with Turing.jl","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"The same problem can be tackled using Turing.jl and the peak shape functions from Spectra as follow.  This offers another way to check that the estimated errors are good for instance, or to use different types of  prior probability distributions on model parameters (as in the quasi-Newton we assume Gaussian priors).","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"You will need to install Turing.jl, which is not a dependency of Spectra.  The code below runs well but it may not be fully optimized. It is just for the sack of example. ","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"Run it on your own computer! If you have suggestions, do not hesitate!","category":"page"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"using Turing\n\n# Define a Bayesian model with priors\n@model function bayesian_peaks(x, y)\n    # Define priors based on peak_types\n\n    # PEAK 1\n    amplitude ~ truncated(Normal(10.016, 0.5), 0.0, Inf)\n    center ~ Normal(34.92, 0.5)\n    width ~ truncated(Normal(10.0, 0.5), 0.0, Inf)\n\n    μ = gaussian(x, [amplitude, center, width])\n    \n    # PEAK 2\n    amplitude2 ~ truncated(Normal(14.9, 0.5), 0.0, Inf)\n    center2 ~ Normal(55.0, 0.5)\n    width2 ~ truncated(Normal(3.0, 0.5), 0.0, Inf)\n    \n    μ2 = lorentzian(x, [amplitude2, center2, width2])\n    \n    # PEAK 3\n    amplitude3 ~ truncated(Normal(25.5, 0.5), 0.0, Inf)\n    center3 ~ Normal(43.0, 10.0)\n    width3 ~ truncated(Normal(2.0, 0.5), 0.0, Inf)\n    lr ~ truncated(Normal(0.39, 0.03), 0.0, 1.0)\n    \n    # Calculate model prediction\n    μ3 = pseudovoigt(x, [amplitude3, center3, width3, lr])\n    \n    # Likelihood\n    σ ~ truncated(Normal(0.2, 0.03), 0.001, Inf)\n    y ~ MvNormal(μ + μ2 + μ3, σ^2 * I)\nend\n\nchain = sample(bayesian_peaks(x_fit, y_fit), NUTS(), 2000, nchains=3, progress=true)","category":"page"},{"location":"PeakFitting.html#Final-remarks","page":"Peak fitting","title":"Final remarks","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"Done, please do check the examples in the Tutorials section for further peak fitting examples. Below you will find the full API of the various functions, including peak shapes, area calculations, fitting algorithms...","category":"page"},{"location":"PeakFitting.html#Functions-API","page":"Peak fitting","title":"Functions API","text":"","category":"section"},{"location":"PeakFitting.html#Peak-fitting-2","page":"Peak fitting","title":"Peak fitting","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"prepare_context\nfit_peaks\nfit_Optim\nfit_qNewton\nplot_fit\nprint_params\nget_peak_results\nbootstrap\nFitContext\nFitResult","category":"page"},{"location":"PeakFitting.html#Spectra.prepare_context","page":"Peak fitting","title":"Spectra.prepare_context","text":"prepare_context(x, y, peaks_info, sigma=ones(length(x)))\n\nCreate a precomputed context for peak fitting operations.\n\nArguments\n\nx::Vector{Float64}: Independent variable values\ny::Vector{Float64}: Observations\npeaks_info::Vector{Tuple}: Peak specifications containing:\nSymbol: Peak type (:gaussian, :lorentzian, :pseudovoigt, :pearson7)\nVector{Float64}: Initial parameters\nVector{Float64}: Parameter uncertainties\nVector{Float64}: Lower bounds\nVector{Float64}: Upper bounds\nsigma::Vector{Float64}: Data uncertainties (default: ones)\n\nReturns\n\nFitContext: Precomputed structure containing matrices, indices, and model function\n\nExamples\n\n'''julia peaksinfo = [ (:gaussian, [1.0, 0.0, 0.5], [0.1, 0.05, 0.1], [-Inf, -1.0, 0.1], [Inf, 1.0, 2.0]), (:lorentzian, [0.5, 0.2, 0.3], [0.1, 0.05, 0.1], [0.0, -0.5, 0.1], [2.0, 0.5, 1.0]) ] ctx = preparecontext(x, peaks_info, sigma) '''\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.fit_peaks","page":"Peak fitting","title":"Spectra.fit_peaks","text":"fit_peaks(ctx::FitContext; backend=:qGN, relax=4, maxiter=100)\n\nPerform peak fitting using specified optimization backend.\n\nArguments\n\nctx::FitContext: Precomputed context from prepare_context\nbackend::Symbol: Optimization method (:Optim or :qGN)\nrelax::Real: Step relaxation factor (qGN only)\nmaxiter::Int: Maximum iterations (qGN only)\n\nReturns\n\nFitResult: Structured results containing:\ncontext::FitContext: Fit context\npeak_results::Vector: Peak results with uncertainties\nparams::Vector{Float64}: Peak parameters\ncovariance::Matrix{Float64}: Covariance matrix\nerrors::Vector{Float64}: 1-sigma standard errors on parameters\ny_calc::Vector{Float64}: Model predictions\nresiduals::Vector{Float64}: Residuals\n\nExamples\n\nx = 1:1.0:100\ny = gaussian(x, 1., 50.0, 5.0) .+ 0.1 * randn(length(x))\npeaks_info = [\n    (:gaussian, [1.0, 50.0, 5.0], [0.1, 0.05, 0.1], [0.0, 40.0, 0.1], [2.0, 60.0, 10.0])\n]\nctx = prepare_context(x, y, peaks_info)\nresult = fit_peaks(ctx; backend=:qGN, relax=4, maxiter=100)\nplot_fit(ctx; result=result.peak_results)\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.fit_Optim","page":"Peak fitting","title":"Spectra.fit_Optim","text":"fit_Optim(ctx::FitContext)\n\nPerform a box constrained fit using the Optim package with the LBFGS algorithm.\n\nThe loss function combines a loss on data and on model prior (eq. 3.46 in Tarantola 2005)\n\nArguments\n\n-ctx: context created by prepare_context\n\nReturns\n\nfitted_params: fitted parameters\nCMpost: covariance matrix of the fitted parameters\nsqrt.(diag(CMpost)): errors of the fitted parameters\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.fit_qNewton","page":"Peak fitting","title":"Spectra.fit_qNewton","text":"fit_qNewton(ctx::FitContext; maxiter=100, relax=5)\n\nPerform a quasi-Newton fit (Tarantola 2005, eq. 3.51)\n\nArguments\n\n-ctx: context created by prepare_context -maxiter: maximum number of iterations -relax: relaxation factor for the step size\n\nReturns\n\nmcurrent: fitted parameters\nCMpost: covariance matrix of the fitted parameters\nsqrt.(diag(CMpost)): errors of the fitted parameters\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.plot_fit","page":"Peak fitting","title":"Spectra.plot_fit","text":"plot_fit(ctx, peak_results=nothing; xlabel=\"X\", ylabel=\"Y\", title=\"Model adjustement\")\n\nreturn a plot of the data and the fit given a ctx context created by prepare_context,  and a result generated by fit_peaks or get_fit_results. If result is not provided, the prior is plotted.\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.print_params","page":"Peak fitting","title":"Spectra.print_params","text":"print_params(peak_results)\n\nprint the parameters after the fit, peakresults is a vector of Named Tuples      (generated by getpeak_results) with the results of the fit.\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.get_peak_results","page":"Peak fitting","title":"Spectra.get_peak_results","text":"get_peak_results(ctx, params, CMpost)\n\nReturns a vector of Named Tuples with the results of the fit.  Values are tied to their errors via the covariance matrix CMpost.\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.bootstrap","page":"Peak fitting","title":"Spectra.bootstrap","text":"bootstrap(x, y, sigma, peaks_info; nb_boot = 100, backend=:qGN, relax=5., maxiter=100)\n\nPerform a bootstrap on the fit.\n\nArguments\n\n-x: x-axis data -y: y-axis data -sigma: data noise -peaks_info: vector of tuples with the peak type and parameters     (peaktype, initialparams, uncertainties, lowerbounds, upperbounds) -nb_boot: number of bootstrap samples -backend: optimization backend, either :Optim or :qGN -relax: relaxation factor for the step size (only used in :qGN) -maxiter: maximum number of iterations (only used in :qGN)\n\nReturns\n\na matrix of size (number of parameters, number of bootstrap samples) with the fitted parameters\na vector of Named Tuples with the results of the fit. Values are tied to their errors via the covariance matrix CMpost.   (peaktype, initialparams, uncertainties, lowerbounds, upperbounds)  \n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.FitContext","page":"Peak fitting","title":"Spectra.FitContext","text":"FitContext type containing all fitting context -x::Vector{Float64}: x data vector. -y::Vector{Float64}: y data vector. -peaks_info::Vector{Tuple}: contains the informations of the peaks of the model. -sigma::Vector{Float64}: error on y. -CD::Matrix{Float64}: data covariance matrix. -ICD::Matrix{Float64}: inverse of the data covariance matrix. -mprior::Vector{Float64}: prior model parameters. -mprior_sigma::Vector{Float64}: uncertainties on prior model parameters. -CM::Matrix{Float64}: model covariance matrix (prior). -ICM::Matrix{Float64}: inverse of the model covariance matrix (prior). -all_lower_bounds::Vector{Float64}: lower boundaries for parameters. -all_upper_bounds::Vector{Float64}: upper boundaries for parameters. -model::Function\n\n\n\n\n\n","category":"type"},{"location":"PeakFitting.html#Spectra.FitResult","page":"Peak fitting","title":"Spectra.FitResult","text":"FitResult type containing all fitting results and metadata context::FitContext: Fit Context. peak_results::Vector: Vector of Named Tuples containing parameters and areas for each peak, with errors. params::Vector{Float64}: Vector of parameters. covariance::Matrix{Float64}: Covariance matrix at the optimal point C_M post. errors::Vector{Float64}: Uncertainties on parameters calculated as sqrt(diag(covariance)). y_calc::Vector{Float64}: Calculated y values, using params. residuals::Vector{Float64}: Difference between calculated and input y values.\n\n\n\n\n\n","category":"type"},{"location":"PeakFitting.html#Peak-shapes","page":"Peak fitting","title":"Peak shapes","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"create_peaks\ngaussian\nlorentzian\npseudovoigt\npearson7","category":"page"},{"location":"PeakFitting.html#Spectra.create_peaks","page":"Peak fitting","title":"Spectra.create_peaks","text":"create_peaks(x::Vector{Float64}, peak_infos::Vector{Dict{Symbol,Any}})\n\nGenerate multiple peaks and their sum from a collection of peak descriptions.\n\nArguments\n\nx::Vector{Float64}: X-axis values where peaks will be evaluated.\npeak_infos::Vector{Dict}: List of dictionaries describing peaks. Each dictionary should contain:\n:type: Peak type (:gaussian, :lorentzian, :pseudovoigt, :pearson7)\nRequired parameters for the specified peak type:\nGaussian: :amplitude, :center, :hwhm\nLorentzian: :amplitude, :center, :hwhm\nPseudoVoigt: :amplitude, :center, :hwhm, :lorentzian_fraction\nPearson7: :amplitude, :center, :hwhm, :exponent\n\nReturns\n\npeaks::Matrix{Float64}: Matrix where each column represents a individual peak\ntotal_spectrum::Vector{Float64}: Sum of all peaks\n\nExamples\n\nx = collect(0:0.1:10)\npeak_infos = [\nDict(:type => :gaussian, :amplitude => 1.0, :center => 5.0, :hwhm => 0.5),\nDict(:type => :lorentzian, :amplitude => 0.8, :center => 7.0, :hwhm => 1.2),\nDict(:type => :pearson7, :amplitude => 0.8, :center => 3.0, :hwhm => 0.2, :exponent => 1.9)\n]\npeaks, total = create_peaks(x, peak_infos)\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.gaussian","page":"Peak fitting","title":"Spectra.gaussian","text":"gaussian(x, amplitude, center, hwhm)\ngaussian(x, p)\n\nGaussian function with parameters amplitude, center, hwhm or a vector p = [amplitude, center, hwhm].\n\nNotes:\n\nthe half-width at half maximum (hwhm) of the gaussian peak is related to the standard deviation sigma by: hwhm = sqrt(2*log(2)) * sigma\ngaussian(x, p) is a shorthand for gaussian(x, p[1], p[2], p[3])\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.lorentzian","page":"Peak fitting","title":"Spectra.lorentzian","text":"lorentzian(x, amplitude, center, hwhm)\nlorentzian(x, p)\n\nLorentzian function with parameters amplitude, center, hwhm or a vector p = [amplitude, center, hwhm].\n\nNotes:\n\nhwhm: half-width at half maximum\nlorentzian(x, p) is a shorthand for lorentzian(x, p[1], p[2], p[3])\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.pseudovoigt","page":"Peak fitting","title":"Spectra.pseudovoigt","text":"pseudovoigt(x, amplitude, center, hwhm, lorentzian_fraction)\npseudovoigt(x, p)\n\nPseudovoigt function with parameters amplitude, center, hwhm, lorentzianfraction or a vector p = [amplitude, center, hwhm, lorentzianfraction].\n\nNotes:\n\nhwhm: half-width at half maximum.\npseudovoigt(x, p) is a shorthand for lorentzian(x, p[1], p[2], p[3], p[4]).\ncalculated as lorentzianfraction*lorentzian + (1 - lorentzianfraction)*gaussian.\nlorentzian_fraction is a value between 0 and 1 that controls the mixing between Gaussian and Lorentzian.\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.pearson7","page":"Peak fitting","title":"Spectra.pearson7","text":"pearson7(x, amplitude, center, hwhm, exponent)\npearson7(x, p)\n\nPearson 7 function with parameters amplitude, center, hwhm, exponent or a vector p = [amplitude, center, hwhm, exponent].\n\nNotes:\n\nEquation is amplitude / (1 + ((x - center)/hwhm)^2 * (2^(1/exponent) - 1))^exponent.\npearson7(x, p) is a shorthand for pearson7(x, p[1], p[2], p[3], p[4]).\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Utilities","page":"Peak fitting","title":"Utilities","text":"","category":"section"},{"location":"PeakFitting.html","page":"Peak fitting","title":"Peak fitting","text":"area_peaks\nbootsample","category":"page"},{"location":"PeakFitting.html#Spectra.area_peaks","page":"Peak fitting","title":"Spectra.area_peaks","text":"area_peaks(peak_type::Symbol, amplitude::Float64, hwhm::Float64; lorentzian_fraction=nothing, exponent=nothing)\n\nCalculate the area under Gaussian, Lorentzian, Pseudo-Voigt, or Pearson VII peaks based on their parameters. Areas are calculated using analytical formulas.\n\nArguments\n\npeak_type::Symbol: The type of peak. Supported types are:\n:gaussian: Gaussian peak.\n:lorentzian: Lorentzian peak.\n:pseudovoigt: Pseudo-Voigt peak (weighted combination of Gaussian and Lorentzian).\n:pearson7: Pearson VII peak.\namplitude::Float64: Amplitude of the peak (maximum height).\nhwhm::Float64: Half-width at half-maximum of the peak.\nlorentzian_fraction::Union{Float64, Nothing}: Lorentzian fraction (for Pseudo-Voigt peaks). Must be in [0, 1]. Default is nothing.\nexponent::Union{Float64, Nothing}: Shape parameter for Pearson VII peaks. Default is nothing.\n\nReturns\n\narea::Float64: The calculated area under the specified peak.\n\nExamples\n\nGaussian Peak\n\nA = 2.0\nhwhm = 0.5\narea_gaussian = peak_area(\"gaussian\", amplitude=A, hwhm=hwhm)\n\nLorentzian Peak\n\nA = 2.0\nhwhm = 0.5\narea_lorentzian = peak_area(\"lorentzian\", amplitude=A, hwhm=hwhm)\n\nPseudo-Voigt Peak\n\nA = 2.0\nhwhm = 0.5\nlorentzian_fraction = 0.5\narea_pseudovoigt = peak_area(\"pseudovoigt\", amplitude=A, hwhm=hwhm, lorentzian_fraction=lorentzian_fraction)\n\nPearson VII Peak\n\nA = 2.0\nhwhm = 0.5\nexponent = 2.0\narea_pearson7 = peak_area(\"pearson7\", amplitude=A, hwhm=hwhm, exponent=exponent)\n\nNotes\n\nGaussian Formula:  textArea = A cdot texthwhm cdot sqrtfracpiln 2\nLorentzian Formula:  textArea = pi cdot A cdot texthwhm\nPseudo-Voigt Formula:  textArea = eta cdot (pi cdot A cdot texthwhm) + (1-eta) cdot (A cdot texthwhm cdot sqrtfracpiln 2)\nPearson VII Formula:  textArea = A cdot texthwhm cdot sqrtfracpi2^1exponent - 1 cdot fracGamma(exponent - 05)Gamma(exponent)\n\nErrors\n\nThrows an error if an unsupported peak_type is provided.\nThrows an error if required parameters for a specific peak type are not provided.\nThrows an error if lorentzian_fraction is not comprised in the [0, 1] interval\n\n\n\n\n\n","category":"function"},{"location":"PeakFitting.html#Spectra.bootsample","page":"Peak fitting","title":"Spectra.bootsample","text":"bootsample(x, y; boottype::String=\"np\", ese=nothing)\n\nInputs\n\nx: the x axis. It can have multiple columns.\ny: the y axis. It can have multiple columns.\n\nOptions\n\nboottype::String = \"np\": type of bootstrapping\n\"np\": non-parametric bootstrapping. Data resampled with replacement. \n\"p\": parametric bootstrapping. Data resampled from the Normal(y, ese) distribution.\nese = nothing: standard errors on y.\n\nOutputs\n\nb_x_f: bootstrapped x sample\nb_y_f: bootstrapped y sample\n\nThe bootstrap function can be embedded in a for loop, and will each time produce a different dataset. Performing K times the bootstrapping and fitting each time the model will allow to estimate the error distribution on the peak parameters. This technic has the advantage of making no prior assumption on the probability distribution functions of parameters errors. However, it is more time consuming that using the covariance matrix.\n\nReferences\n\nEfron, B. 1979. “Bootstrap Methods: Another Look at the Jackknife.” The Annals of Statistics 7 (1): 1–26.\nEfron, Bradley. 1981. “Nonparametric Estimates of Standard Error: The Jackknife, the Bootstrap and Other Methods.” Biometrika 68 (3): 589–99. doi:10.1093/biomet/68.3.589.\nEfron, B., and Tibshirani, R. 1994. An Introduction to the Bootstrap. CRC press.\n\n\n\n\n\n","category":"function"},{"location":"HelperFunctions.html#Helper-Functions","page":"Helper Functions","title":"Helper Functions","text":"","category":"section"},{"location":"HelperFunctions.html","page":"Helper Functions","title":"Helper Functions","text":"Below are listed some helper functions for reference.","category":"page"},{"location":"HelperFunctions.html","page":"Helper Functions","title":"Helper Functions","text":"normal_dist\npoly\nxshift_direct","category":"page"},{"location":"HelperFunctions.html#Spectra.normal_dist","page":"Helper Functions","title":"Spectra.normal_dist","text":"normal_dist(x, amplitude, mean, sigma)\nnormal_dist(x, p)\n\nNormal distribution with parameters amplitude, mean, sigma or a vector p = [amplitude, mean, sigma].\n\nNotes:\n\nnormaldist(x, p) is a shorthand for normaldist(x, p[1], p[2], p[3])\n\n\n\n\n\n","category":"function"},{"location":"HelperFunctions.html#Spectra.poly","page":"Helper Functions","title":"Spectra.poly","text":"poly(p::Vector{Float64},x::Vector{Float64})\n\nBuild a polynomial curve given parameters p::Vector{Float64} at the x::Vector{Float64} values.\n\nFor a linear curve, p = [1.0,1.0], for a second order polynomial, p = [1.0,1.0,1.0], etc.;\n\n\n\n\n\n","category":"function"},{"location":"HelperFunctions.html#Spectra.xshift_direct","page":"Helper Functions","title":"Spectra.xshift_direct","text":"xshift_direct(original_x::Array{Float64}, original_y::Array{Float64}, p::Float64)\n\nCorrect a spectrum for a p shift in X. Used in xshift_correction.\n\nInputs\n\noriginal_x: Array{Float64}\n\tx values\noriginal_y: Array{Float64}\n\ty values associated with x\np: Array{Float64}\n\tvalue of how much x should be shifted\n\nOutputs\n\noriginal_x: Array{Float64}\n\tsame as input\ncorrected_y: Array{Float64}\n\tthe y values corrected from the p shift in original_x\np: Array{Float64}\n\tsame as input.\n\n\n\n\n\n","category":"function"},{"location":"MachineLearning.html#Machine-Learning","page":"Machine Learning","title":"Machine Learning","text":"","category":"section"},{"location":"MachineLearning.html","page":"Machine Learning","title":"Machine Learning","text":"Spectra calls the rampy.mlregressor and rampy.mlexplorer functions to provide easy-to-use access to some machine learning algorithms from the SciKit Learn python library.","category":"page"},{"location":"MachineLearning.html","page":"Machine Learning","title":"Machine Learning","text":"More advanced ML treatments can be done within the Julia ecosystem (e.g. using Flux, MXNet, Tensorflow etc.), but this is outsite Spectra.","category":"page"},{"location":"MachineLearning.html","page":"Machine Learning","title":"Machine Learning","text":"mlregressor\nmlexplorer","category":"page"},{"location":"MachineLearning.html#Spectra.mlregressor","page":"Machine Learning","title":"Spectra.mlregressor","text":"mlregressor(x::Array{Float64},y::Array{Float64};X_test::Array{Float64}=[0.0],y_test::Array{Float64}=[0.0],test_sz=0.3,scaler=\"MinMaxScaler\",rand_state=42)\n\nUse machine learning algorithms from scikit learn to perform regression between spectra and an observed variable.\n\nThis calls the rampy.mlregressor function and creates a Python object. Any algorithm parameter can be modified in the model object.\n\nExamples\n\nusing Spectra\nmodel = mlregressor(X,y)\nmodel.algorithm = \"SVM\"\nmodel.user_kernel = \"poly\"\nmodel.fit()\ny_new = model.predict(X_new)\n\nDocstring from rampy.mlexporer\n\nAttributes\n\nx : {array-like, sparse matrix}, shape = (nsamples, nfeatures)\n\nSpectra; n_features = n_frequencies.\n\ny : array, shape = (n_samples,)\n\nReturns predicted values.\n\nXtest : {array-like, sparse matrix}, shape = (nsamples, n_features)\n\nspectra organised in rows (1 row = one spectrum) that you want to use as a testing dataset. THose spectra should not be present in the x (training) dataset. The spectra should share a common X axis.\n\nytest : array, shape = (nsamples,)\n\nthe target that you want to use as a testing dataset. Those targets should not be present in the y (training) dataset.\n\nalgorithm : String,\n\n\"KernelRidge\", \"SVM\", \"LinearRegression\", \"Lasso\", \"ElasticNet\", \"NeuralNet\", \"BaggingNeuralNet\", default = \"SVM\"\n\nscaling : Bool\n\nTrue or False. If True, data will be scaled during fitting and prediction with the requested scaler (see below),\n\nscaler : String\n\nthe type of scaling performed. Choose between MinMaxScaler or StandardScaler, see [http://scikit-learn.org/stable/modules/preprocessing.html](http://scikit-learn.org/stable/modules/preprocessing.html) for details. Default = \"MinMaxScaler\".\n\ntest_size : float\n\nthe fraction of the dataset to use as a testing dataset; only used if X_test and y_test are not provided.\n\nrand_state : Float64\n\nthe random seed that is used for reproductibility of the results. Default = 42.\n\nparam_kr : Dictionary\n\ncontain the values of the hyperparameters that should be provided to KernelRidge and GridSearch for the Kernel Ridge regression algorithm.\n\nparam_svm : Dictionary\n\ncontaing the values of the hyperparameters that should be provided to SVM and GridSearch for the Support Vector regression algorithm.\n\nparam_neurons : Dictionary\n\ncontains the parameters for the Neural Network (MLPregressor model in sklearn).\nDefault= dict(hidden_layer_sizes=(3,),solver = 'lbfgs',activation='relu',early_stopping=True)\n\nparam_bagging : Dictionary\n\ncontains the parameters for the BaggingRegressor sklearn function that uses a MLPregressor base method.\nDefault= dict(n_estimators=100, max_samples=1.0, max_features=1.0, bootstrap=True,\n\t\t\t\tbootstrap_features=False, oob_score=False, warm_start=False, n_jobs=1, random_state=rand_state, verbose=0)\n\nprediction_train : Array{Float64}\n\nthe predicted target values for the training y dataset.\n\nprediction_test : Array{Float64}\n\nthe predicted target values for the testing y_test dataset.\n\nmodel : Scikit learn model\n\nA Scikit Learn object model, see scikit learn library documentation.\n\nX_scaler :\n\nA Scikit Learn scaler object for the x values.\n\nY_scaler :\n\nA Scikit Learn scaler object for the y values.\n\nRemarks\n\nFor details on hyperparameters of each algorithms, please directly consult the documentation of SciKit Learn at:\n\nhttp://scikit-learn.org/stable/\n\nFor Support Vector and Kernel Ridge regressions, mlregressor performs a cross_validation search with using 5 KFold cross validators.\n\nIf the results are poor with Support Vector and Kernel Ridge regressions, you will have to tune the paramgridkr or paramgridsvm dictionnary that records the hyperparameter space to investigate during the cross validation.\n\nResults for machine learning algorithms can vary from run to run. A way to solve that is to fix the random_state. For neural nets, results from multiple neural nets (bagging technique) may also generalise better, such that it may be better to use the BaggingNeuralNet function.\n\n\n\n\n\n","category":"function"},{"location":"MachineLearning.html#Spectra.mlexplorer","page":"Machine Learning","title":"Spectra.mlexplorer","text":"mlexplorer(x::Array{Float64})\n\nUse machine learning algorithms from scikit learn to explore spectroscopic datasets. Performs automatic scaling and train/test split before NMF or PCA fit.\n\nExamples\n\n```julia-repl\njulia> explo = mlexplorer(X) # X is an array of signals built by mixing two partial components\njulia> explo.algorithm = \"NMF\" # using Non-Negative Matrix factorization\njulia> explo.nb_compo = 2 # number of components to use\njulia> explo.test_size = 0.3 # size of test set\njulia> explo.scaler = \"MinMax\" # scaler\njulia> explo.fit() # fitting!\njulia> W = explo.model.transform(explo.X_train_sc) # getting the mixture array\njulia> H = explo.X_scaler.inverse_transform(explo.model.components_) # components in the original space\njulia> plot(X,H.T) # plot the two components\n```\n\nDocstring from rampy.mlexporer\n\nAttributes\n\nx : {array-like, sparse matrix}, shape = (nsamples, nfeatures)\n\nSpectra; n_features = n_frequencies.\n\nXtest : {array-like, sparse matrix}, shape = (nsamples, n_features)\n\nspectra organised in rows (1 row = one spectrum) that you want to use as a testing dataset. THose spectra should not be present in the x (training) dataset. The spectra should share a common X axis.\n\nalgorithm : String,\n\n\"PCA\", \"NMF\", default = \"PCA\"\n\nscaling : Bool\n\nTrue or False. If True, data will be scaled prior to fitting (see below),\n\nscaler : String\n\nthe type of scaling performed. Choose between MinMaxScaler or StandardScaler, see [http://scikit-learn.org/stable/modules/preprocessing.html](http://scikit-learn.org/stable/modules/preprocessing.html) for details. Default = \"MinMaxScaler\".\n\ntest_size : float\n\nthe fraction of the dataset to use as a testing dataset; only used if X_test and y_test are not provided.\n\nrand_state : Float64\n\nthe random seed that is used for reproductibility of the results. Default = 42.\n\nmodel : Scikit learn model\n\nA Scikit Learn object model, see scikit learn library documentation.\n\nRemarks\n\nFor details on hyperparameters of each algorithms, please directly consult the documentation of SciKit Learn at:\n\nhttp://scikit-learn.org/stable/\n\nResults for machine learning algorithms can vary from run to run. A way to solve that is to fix the random_state.\n\n\n\n\n\n","category":"function"},{"location":"References.html#References","page":"References","title":"References","text":"","category":"section"},{"location":"References.html","page":"References","title":"References","text":"Baek, S.-J., A. Park, Y.-J. Ahn, and J. Choo 2015. Baseline correction using asymmetrically reweighted penalized least squares smoothing, Analyst, 140(1), 250–257, doi:10.1039/C4AN01061B.\nBrooker et al. 1988 Assessment of correction procedures for reduction of Raman spectra. Journal of Raman Spectroscopy 19(2), 71-78.\nEfron, B. 1979. “Bootstrap Methods: Another Look at the Jackknife.” The Annals of Statistics 7 (1): 1–26.\nEfron, Bradley. 1981. “Nonparametric Estimates of Standard Error: The Jackknife, the Bootstrap and Other Methods.” Biometrika 68 (3): 589–99. doi:10.1093/biomet/68.3.589.\nEfron, B., and Tibshirani, R. 1994. An Introduction to the Bootstrap. CRC press.\nEilers, P. H. C. 2003. A Perfect Smoother, Anal. Chem., 75(14), 3631–3636, doi:10.1021/ac034173t.\nEilers, P. H. C. and Boelens H. F. M., 2005. Baseline Correction with Asymmetric Least Squares Smoothing.\nGaleener, F. L., and Sen, P. N. 1978. “Theory of the First-Order Vibrational Spectra of Disordered Solids.” Physical Review B 17 (4): 1928–33.\nHehlen, B. 2010. “Inter-Tetrahedra Bond Angle of Permanently Densified Silicas Extracted from Their Raman Spectra.” Journal of Physics: Condensed Matter 22 (2): 025401.\nLe Losq, C., Neuville, D.R., Moretti, R., and Roux, J. (2012) Determination of water content in silicate glasses using Raman spectrometry: Implications for the study of explosive volcanism. American Mineralogist, 97, 779–790.\nLe Losq C., Neuville D. R., Florian P., Henderson G. S. and Massiot D., 2014, The role of Al3+ on rheology and structural changes in sodium silicate and aluminosilicate glasses and melts. Geochimica et Cosmochimica Acta 126, 495-517.\nNeuville, D. R., and B. O. Mysen. 1996. “Role of Aluminium in the Silicate Network: In Situ, High-Temperature Study of Glasses and Melts on the Join SiO₂-NaAl0₂.” Geochimica et Cosmochimica Acta 60: 1727–37.\nMysen, B. O., L. W. Finger, D. Virgo, and F. A. Seifert. 1982. “Curve-Fitting of Raman Spectra of Silicate Glasses.” American Mineralogist 67: 686–95.\nShuker, Reuben, and Robert Gammon. 1970. “Raman-Scattering Selection-Rule Breaking and the Density of States in Amorphous Materials.” Physical Review Letters 25 (4): 222–25.\nTarantola, A. (2005) Inverse problem theory and methods for model parameter estimation, 342 p. Society for Industrial and Applied Mathematics, Philadelphia, PA.\nWoltring, 1986, A FORTRAN package for generalized, cross-validatory spline smoothing and differentiation. Adv. Eng. Softw. 8, 104-113.","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"EditURL = \"../../../examples/Smoothing.jl\"","category":"page"},{"location":"examples/Smoothing.html#Smoothing-data","page":"Smoothing data","title":"Smoothing data","text":"","category":"section"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"This notebook highlights how signals can be smoothed with the smooth function.","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"using Plots, Spectra, Random, Statistics","category":"page"},{"location":"examples/Smoothing.html#Signal-generation","page":"Smoothing data","title":"Signal generation","text":"","category":"section"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"x = collect(0:0.5:100)\npeak_infos = [\n    Dict(:type => :gaussian, :amplitude => 10.0, :center => 40.0, :hwhm => 5.0),\n    Dict(:type => :gaussian, :amplitude => 20.0, :center => 60.0, :hwhm => 15.0),\n]\npeaks, total = create_peaks(x, peak_infos)\n\n# some background: a large gaussian + linear\nbkg = 10.0 .* sin.(x ./ 50.0) + 0.1 .* x\n\n# real data have noise: here some Gaussian noise\nnoise = 2.0 * randn!(ones(size(x, 1)))\n\n# the observed signal is:\ny = total + noise + bkg\n\n# Let's have a look at it using Plots:\np1 = scatter(x, y; label=\"signal\",\n    xlabel=\"X\", ylabel=\"Y\",\n    legend=:topleft)\nsavefig(\"smoothing_1.svg\"); nothing #hide","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"(Image: )","category":"page"},{"location":"examples/Smoothing.html#Smoothing","page":"Smoothing data","title":"Smoothing","text":"","category":"section"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"Now we loop other available methods to smooth the signal with default parameters. We could use window-based smoother for instance. For them, you can tune the window_length parameter to change the size of the smoothing window. Warning, it must be a positive odd integer.","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"methods_ = [\"flat\", \"hanning\", \"hamming\", \"bartlett\", \"blackman\"]\nese_methods_ = Float64[]\nfor i in methods_\n    y_smo = smooth(x, y, method=i, window_length=19)\n    plot!(x, y_smo, label=i)\n    push!(ese_methods_, sum((y - y_smo).^2))\nend\nsavefig(\"smoothing_2.svg\"); nothing #hide","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"(Image: )","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"We can also use Savitzky-Golay filter, Whittaker smoother, or GCVSpline. Again, changing defaults e.g. for savgol or whittaker may improve (or not) your smoothed signals! You need to try tuning them. Here we are doing a lazy job and use defaults. The most automatic method should be gcvspline because it uses Generalized-Cross-Validation (GCV) to find a good balance between signal smoothness and fitting.","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"methods_bis_ = [\"savgol\", \"whittaker\", \"gcvspline\"]","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"redo another plot for having a clean graph","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"p2 = scatter(x, y; label=\"signal\",\n    xlabel=\"X\", ylabel=\"Y\",\n    legend=:topleft)\nfor i in methods_bis_\n    y_smo = smooth(x, y, method=i, window_length=21, polyorder=2, lambda=1e2)\n    plot!(x, y_smo, label=i)\n    push!(ese_methods_, sum((y - y_smo).^2))\nend\nsavefig(\"smoothing_3.svg\"); nothing #hide","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"(Image: )","category":"page"},{"location":"examples/Smoothing.html#Compare-performances","page":"Smoothing data","title":"Compare performances","text":"","category":"section"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"We can compare the performances of the different methods using a bar plot:","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"push!(methods_, methods_bis_...)\np_bar = bar(ese_methods_, xticks=(1:8,methods_),\nxlabel=\"Smoothing method\", ylabel=\"MSE between real and smoothed signal\")\nsavefig(\"smoothing_4.svg\"); nothing #hide","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"(Image: )","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"","category":"page"},{"location":"examples/Smoothing.html","page":"Smoothing data","title":"Smoothing data","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"EditURL = \"../../../examples/Baseline_examples.jl\"","category":"page"},{"location":"examples/Baseline_examples.html#Baseline-examples","page":"Baseline examples","title":"Baseline examples","text":"","category":"section"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"Charles Le Losq","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"August 2017; updated March 2025","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"Examples of using the baseline function with various algorithms (splines, polynomials, ALS, arPLS...)","category":"page"},{"location":"examples/Baseline_examples.html#Importing-the-relevant-libraries","page":"Baseline examples","title":"Importing the relevant libraries","text":"","category":"section"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"Spectra to process our data, Plots to plot the results, and Random to generate random numbers","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"using Spectra\nusing Plots;\ngr()\nusing Random","category":"page"},{"location":"examples/Baseline_examples.html#Creating-a-fake-signal-to-know-the-ground-truth","page":"Baseline examples","title":"Creating a fake signal to know the ground truth","text":"","category":"section"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"We use the create_peaks function to generate 5 gaussian peaks","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"# Our arbitrary X axis is\nx = collect(50:1.0:500)\n\n# and now our signal can be created with create_peaks() like this:\npeak_infos = [\n    Dict(:type => :gaussian, :amplitude => 20.0, :center => 150.0, :hwhm => 15.0),\n    Dict(:type => :gaussian, :amplitude => 100.0, :center => 250.0, :hwhm => 5.0),\n    Dict(:type => :gaussian, :amplitude => 50.0, :center => 450.0, :hwhm => 1.0),\n    Dict(:type => :gaussian, :amplitude => 20.0, :center => 350.0, :hwhm => 30.0),\n    Dict(:type => :gaussian, :amplitude => 30.0, :center => 460.0, :hwhm => 5.0),\n]\npeaks, total = create_peaks(x, peak_infos)\n\n# some background: a large gaussian + linear\nbkg = 10.0 .* sin.(x ./ 50.0) + 0.1 .* x\n\n# real data have noise: here some Gaussian noise\nnoise = 2.0 * randn!(ones(size(x, 1)))\n\n# the observed signal is:\ny = total + noise + bkg\n\n# Let's have a look at it using Plots:\np1 = plot(x, y; label=\"signal\", xlabel=\"X\", ylabel=\"Y\")\nsavefig(\"baseline_1.svg\"); nothing #hide","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"(Image: )","category":"page"},{"location":"examples/Baseline_examples.html#Calling-the-baseline()-function-to-remove-the-background","page":"Baseline examples","title":"Calling the baseline() function to remove the background","text":"","category":"section"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"see documentation at http://charlesll.github.io/Spectra.jl/stable/PreProcessing/#baseline-subtraction","category":"page"},{"location":"examples/Baseline_examples.html#ROI-based-methods","page":"Baseline examples","title":"ROI-based methods","text":"","category":"section"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"The baseline function can be used to remove the background from a signal. The function takes the following arguments:","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"x: the x-axis of the signal\ny: the y-axis of the signal\nroi: if required, the regions of interest where the signal is located\nmethod: the method to use to remove the background","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"For polynomial and spline methods, the roi argument is required and should be a n x 2 array with the start and end of the region of interest. It choice is thus important. It defines the portions of the spectra where we want to fit the signal background. roi should be an n x 2 array, see baseline documentation.","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"# Here we use the following ROIs:\nroi = [0 100.0; 200 220; 280 290; 420 430; 480 490]\n\n# Using those ROI, we call the Dspline method from Dierckx.jl, setting ourselfs the smoothing parameter s=1.3.\n# The smoothing parameter s is a trade-off between the smoothness of the spline and the closeness of the fit to the data.\ny_dspl, bas_dspl = baseline(x, vec(y); roi=roi, method=\"Dspline\", s=1.3)\n\n# We could use also the GCV method to decide of the smoothing spline coefficient automatically. This\n# is what does the \"gcvspline\" method. Note that you can also impose s for this gcvspline method.\ny_gcvspl, bas_gcvspl = baseline(x, vec(y); roi=roi, method=\"gcvspline\")\n\n# Now we also implemented the Whittaker smoother as a baseline method. Basically, we use the smoother on the signal in the ROIs, and it works fairly well!\ny_whitt, bas_whitt = baseline(x, y; roi=roi, method=\"whittaker\", lambda=1.0e5)\n\n# plotting the baselines\nplot!(x, [bas_dspl, bas_gcvspl, bas_whitt]; labels=[\"Dspline\" \"gcvspline\" \"whittaker\"])\nsavefig(\"baseline_2.svg\"); nothing #hide","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"(Image: )","category":"page"},{"location":"examples/Baseline_examples.html#ROI-free-methods","page":"Baseline examples","title":"ROI-free methods","text":"","category":"section"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"The baseline function can also be used to remove the background from a signal without specifying the ROI. For that, you can use the following methods:","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"als: the Asymmetric Least Squares method\narPLS: the Adaptive Penalized Least Squares method\ndrPLS: the Damped Regularized Penalized Least Squares method","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"y_als, bas_als = baseline(x, y; roi=roi, method=\"als\", p=0.01, lambda=10.0^5, niter=10)\ny_arpls, bas_arpls = baseline(x, y; method=\"arPLS\", p=0.01, lambda=10.0^6, ratio=0.01)\ny_drpls, bas_drpls = baseline(x, y; method=\"drPLS\", ratio=0.1, lambda=10.0^6)\n\n# plotting the baselines\nplot!(x, [bas_als, bas_arpls, bas_drpls]; labels=[\"als\" \"arPLS\" \"drPLS\"])\nsavefig(\"baseline_3.svg\"); nothing #hide","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"(Image: )","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"","category":"page"},{"location":"examples/Baseline_examples.html","page":"Baseline examples","title":"Baseline examples","text":"This page was generated using Literate.jl.","category":"page"},{"location":"PreProcessing.html#Data-Processing","page":"Data Processing","title":"Data Processing","text":"","category":"section"},{"location":"PreProcessing.html#Introduction","page":"Data Processing","title":"Introduction","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Spectra allows you to perform several processing steps on x-y spectral data. Below we will showcase short examples, and then you will find the documentation of the variosu functions you may want to use!","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"As a starting point and for the sack of example, we create two synthetic signals to play with. They will be Gaussian signals randomly sampled along two different X axis, with noise and increasing backgrounds. One of them will also have a strong spike!","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"# Signal creation\nusing Spectra, Plots\n\n# we create a fake signal with \nx_1 = rand(1000)*100\nx_2 = rand(1000)*100\n\n# create a signal that is the combination of two gaussian peaks plus a background\nbackground_1 = 0.08 * x_1\nbackground_2 = 0.03 * x_2\n\n# some noise\nnoise_1 = 0.5*randn(1000)\nnoise_2 = 0.3*randn(1000)\n\n# the full toy signals\ny_1 = gaussian(x_1, 10.0, 40., 5.) .+ background_1 .+ noise_1\ny_2 = gaussian(x_2, 20.0, 60., 9.) .+ background_2 .+ noise_2\n\n# one of them will have a spike!\ny_1[600] = 250.0 \n\n# make a plot of our two spectra\nscatter(x_1, y_1)\nscatter!(x_2, y_2)\nsavefig(\"fp_1.svg\"); nothing #hide","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"(Image: )","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"We can do the following steps (not necessarily in this order):","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"correct_xshift allows correcting X-axis shifts of your spectra from a reference value (e.g. silicon wafer reference in Raman spectroscopy). \nnm_to_invcm or invcm_to_nm convert the X axis between nanometers (nm) and wavenumbers (cm^-1).\nflipsp sort the X-axis (this is necessary for some algorithms).\nresample allows getting our spectra on the same X axis for convenience. \ndespiking remove spikes in the signal. \nbaseline allows removing the background.\nsmooth allows smoothing signals.\ntlcorrection corrects Raman spectra for temperature and laser wavelength effects.\nnormalise allows normalising the spectra. \nextract_signal can extract specific portions of a signal.","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Thanks to Julia's multiple dispatch, those functions support different types of inputs. Of course you will receive different outputs, see the individual documentation of each function for further details. This is quite convenient as this avoid you to write your own loops to process many spectra at once.","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Let's now use some of those functions below on the signal generated above.","category":"page"},{"location":"PreProcessing.html#Sort-X-Axis","page":"Data Processing","title":"Sort X Axis","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"We can sort the data by passing an array of spectra to flipsp. After that we should have not problem plotting things with lines for instance!","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"spectrum_1 = flipsp([x_1 y_1])\nspectrum_2 = flipsp([x_2 y_2])\nplot(spectrum_1[:,1], spectrum_1[:, 2])\nplot!(spectrum_2[:,1], spectrum_2[:, 2])\nsavefig(\"fp_2.svg\"); nothing #hide","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"(Image: )","category":"page"},{"location":"PreProcessing.html#Remove-spikes","page":"Data Processing","title":"Remove spikes","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"OK, the plot above reveals a strong spike in one of the signals. We will treat actually both signals with despiking to remove possible spikes from the signals, using the default parameters.   In summary, with the default settings, despiking checks if any points in a spectrum differ by more than 3 sigma from the mean value of the 4 neighboring points.   You can change the default values to adjust the threshold (for more or less than 3-sigma), or to modify the number of neighboring points considered.","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"y_1 = despiking(x_1, y_1)\ny_2 = despiking(x_2, y_2)","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"tip: Tip\nYou could also call despiking on the collection of spectra ascollection_spectra = [[x_1 y_1], [x_2 y_2]] \nys = despiking(collection_spectra)","category":"page"},{"location":"PreProcessing.html#Resample-spectra","page":"Data Processing","title":"Resample spectra","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Using resample, we can resample a spectrum or spectra on a user-defined X axis by calling","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"x_new = collect(0.:0.5:100)\ny_new = resample(x, y, x_new)","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"By default, resample uses a linear interpolation method from the DataInterpolations.jl package, but you can specify other methods available at https://docs.sciml.ai/DataInterpolations/stable/methods/.","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"If you have multiple spectra, it is here very interesting to provide a collection of those spectra because you will then receive an array of spectra in output, all sampled on the same X axis.","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Continuing on the example shown above, we can do:","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"x_new = collect(0.:0.5:100)\nspectra_ = [[x_1 y_1], [x_2 y_2]]\nspectra_same_x = resample(spectra_, x_new)\nplot(x_new, spectra_same_x)\nsavefig(\"fp_3.svg\"); nothing #hide","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"(Image: )","category":"page"},{"location":"PreProcessing.html#Baseline-subtraction","page":"Data Processing","title":"Baseline subtraction","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Baseline subtraction is performed using baseline, which serves as the main API and wraps several dedicated baseline correction algorithms. Similarly to the other functions, you can pass x and y vectors or a x vectors and an array of y spectra. ","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Continuing with our example, we will do here:","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"ys_corrected, ys_baselines = baseline(x_new, spectra_same_x, method=\"arPLS\")\np1 = plot(x_new, spectra_same_x)\nplot!(x_new, ys_baselines, labels=[\"background 1\" \"background 2\"])\nsavefig(\"fp_4.svg\"); nothing #hide","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"(Image: )","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Other methods are available, see the Tutorials and baseline function documentation  for further details!","category":"page"},{"location":"PreProcessing.html#Smoothing","page":"Data Processing","title":"Smoothing","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Spectra smoothing can be achieved with the smooth function, which supports several algorithms: ","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Whittaker smoother: Custom Julia implementation based on the Matlab code of Eiler (2003). It supports both equally and unequally spaced X values.\nSavitzky-Golay Smoother: Provided by the SavitskyGolay.jl library. \nGCV cubic spline smoother: From the DataInterpolations.jl library.\nWindow-based smoothers: leverage the DSP.jl library.","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"For fine control over smoothing parameters, you can use the whittaker function directly, allowing you to change weights w or the smoothing order d (also possible in smooth).","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Continuing with our example, we will pass the matrix of baseline corrected signals to smooth like:","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"smoothed_y = smooth(x_new, spectra_same_x; method=\"gcvspline\")\n\np1 = plot(x_new, spectra_same_x)\nplot!(x_new, smoothed_y, labels=[\"smoothed 1\" \"smoothed 2\"])\nsavefig(\"fp_5.svg\"); nothing #hide","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"(Image: )","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Other methods are available, see the Tutorials and smooth function documentation  for further details!","category":"page"},{"location":"PreProcessing.html#Signal-normalisation","page":"Data Processing","title":"Signal normalisation","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Using normalise, you can normalise signals to their maximum intensity (method=\"intensity\"), the area under the curve (method=\"area\") or to their minimum and maximum values (minimum will be set to 0, maximum to 1) (method=\"minmax\").","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"For instance, continuing with our example, we can do:","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"normalised_ys = normalise(spectra_same_x, method=\"intensity\")\np1 = plot(x_new, normalised_ys)\nsavefig(\"fp_6.svg\"); nothing #hide","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"(Image: )","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"If you want to normalize the signals by their areas, you have to pass x values too, like:","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"normalised_y = normalise(y_matrix, x, method=\"intensity\")","category":"page"},{"location":"PreProcessing.html#Signal-extraction","page":"Data Processing","title":"Signal extraction","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"Extract signals in specific regions of interest using extract_signal. You can pass associated x and y values, a single spectrum in the form of a [x y] matrix, or a list of [x y] matrices.","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"For instance, for a single signal in which we want the values between 40 and 60, we would write:","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"roi = [[40. 60.]]\nextracted_x, extracted_y, indices = extract_signal(x, y, roi)","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"You can also extract the signals in different portions by using a matrix for the regions of interest. For instance, to extract signals between 20 and 40, and 60 and 80, we can do:","category":"page"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"roi = [[20. 40.]; [60. 80.]]\nextracted_x, extracted_y, indices = extract_signal(x, y, roi)","category":"page"},{"location":"PreProcessing.html#Functions-API","page":"Data Processing","title":"Functions API","text":"","category":"section"},{"location":"PreProcessing.html","page":"Data Processing","title":"Data Processing","text":"correct_xshift\nnm_to_invcm\ninvcm_to_nm\nflipsp\nresample\ndespiking\ntlcorrection\nnormalise\nextract_signal\nbaseline\nals_baseline\narPLS_baseline\ndrPLS_baseline\nrubberband_baseline\nsmooth\nwhittaker","category":"page"},{"location":"PreProcessing.html#Spectra.correct_xshift","page":"Data Processing","title":"Spectra.correct_xshift","text":"correct_xshift(x::Vector{Float64}, y::Union{Vector{Float64}, Matrix{Float64}}, shift::Float64)\ncorrect_xshift(sps::Vector{<:Matrix}, shift::Float64)\n\nReturn the signal(s) corrected from a given linear shift at the same x location as the input.\n\nSignals can be provided as y (vector or an array of ys values) for a given x vector, or as a list of [x y] arrays of signals.\n\nDepending on the arguments, it either returns a new vector or array of y at  the position x, or a new list of corrected [x y] spectra.\n\nThis would be typically used to correct a linear shift in x on Raman spectra:  for instance you measured the Si wafer peak at 522.1 cm-1 while you know it is at 520.7 cm-1.  Therefore you will call this function to correct your spectra from this shift, without affecting the x values.\n\nExamples\n\nusing Spectra\n\n# for a vector y\nx = [0., 1., 2., 3.]\ny = 2*x\nshift = -0.1\n\nnew_y = correct_xshift(x, y, shift)\n\n# for an array of y\nx2 = [0.5, 1.3, 2.0, 4.5]\ny2 = [2*x 3*x 4*x]\nnew_y = correct_xshift(x, y2, shift)\n\n# for a list of x-ys\nold_spectra_list = [[x, y], [x2, y2]]\nnew_spectra_list = corrected(old_spectra_list, shift)\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.nm_to_invcm","page":"Data Processing","title":"Spectra.nm_to_invcm","text":"nm_to_invcm(x::Vector{Float64}; laser_nm = 532.0)\n\nConvert absolute wavelengths in nanometers (nm) to Raman shifts in inverse centimeters (cm⁻¹),  given laser_nm, the wavelength of the excitation laser in nanometers.\n\nExamples\n\nIf using a 532 nm laser line, you will do:\n\nx_wavelength_nm = collect(557:1.0:560) # unit = nm\nx_inv_cm = nm_to_invcm(x_wavelength_nm; laser_nm = 532.0)\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.invcm_to_nm","page":"Data Processing","title":"Spectra.invcm_to_nm","text":"invcm_to_nm(shift_inv_cm::Vector{Float64}; laser_nm=532.0)\n\nConvert Raman shifts in inverse centimeters (cm⁻¹) to absolute wavelengths in nanometers (nm),  given laser_nm, the wavelength of the excitation laser in nanometers.\n\nExamples\n\nIf using a 532 nm laser line, you will do:\n\nx_inv_cm = collect(557:1.0:560) # unit = cm^-1\nx_wavelength_nm = invcm_to_nm(x_inv_cm; laser_nm = 532.0)\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.flipsp","page":"Data Processing","title":"Spectra.flipsp","text":"flipsp(spectra::Union{Matrix{Float64}, Vector{<:Matrix}})\n\nReturn the spectrum array or a list of spectra arrays sorted by their first column values (increasing x).\n\nExamples\n\n\n# create some unsorted signals\nx = [0., 2.,5.,-1]\nx2 = [0., 2.,5.,-1, 3., -10.]\ny = 2*x\ny2 = 2*x2\n\n# the arrays of signals\nsignal_1 = [x y]\nsignal_2 = [x2 y2]\n\n# a list of signal arrays\nsps = [signal_1, signal_2]\n\n# flip one signal array\nflipsp(signal_1)\n\n# you can also do this\nflipsp([x y])\n\n# flip the list of signal arrays\nflipsp(sps)\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.resample","page":"Data Processing","title":"Spectra.resample","text":"resample(x::Vector{Float64}, y::Union{Vector{Float64}, Matrix{Float64}}, x_new::Vector{Float64}; method::String=\"LinearInterpolation\")\nresample(multiple_spectra::Vector{<:Matrix{Float64}}, x_new::Vector{Float64}; method::String=\"LinearInterpolation\")\n\nResample a signal or signals onto a new set of x-coordinates using interpolation.\n\nArguments\n\nx::Vector{Float64}: The original x-coordinates corresponding to the input signal(s).\ny::Union{Vector{Float64}, Matrix{Float64}}: The input signal(s) to resample.\nIf y is a vector, it represents a single signal.\nIf y is a matrix, each column represents a separate signal.\nmultiple_spectra::Vector{<:Matrix{Float64}}: A collection of spectra where each spectrum is a matrix with two columns:\nFirst column: x-coordinates\nSecond column: y-values (signal intensities)\nx_new::Vector{Float64}: The new x-coordinates onto which the signal(s) will be resampled.\nmethod::String=\"LinearInterpolation\": The interpolation method to use. Options include:\nmethods available in the DataInterpolations.jl package: https://docs.sciml.ai/DataInterpolations/stable/methods/.\n\nReturns\n\nFor single signal (vector) input: A vector of resampled values (Vector{Float64}).\nFor multiple signals (matrix) input: A matrix where each column corresponds to the resampled values of the respective input column (Matrix{Float64}).\nFor collection of spectra input: A matrix where each column contains the resampled y-values for the corresponding spectrum in the input collection.\n\nErrors\n\nThrows an error if an unsupported interpolation method is specified.\nThrows an error if the dimensions of x and y do not match.\n\nMethods\n\nThis function provides three methods to handle different input types:\n\nSingle signal: resample(x::Vector{Float64}, y::Vector{Float64}, x_new::Vector{Float64})\nMultiple signals with common x-axis: resample(x::Vector{Float64}, y::Matrix{Float64}, x_new::Vector{Float64})\nCollection of spectra: resample(multiple_spectra::Vector{<:Matrix{Float64}}, x_new::Vector{Float64})\n\nNotes\n\nUses the DataInterpolations.jl package for interpolation.\nExtrapolation beyond the range of x is handled using the option extrapolation_right=ExtrapolationType.Extension and extrapolation_left=ExtrapolationType.Extension.\nFor the collection of spectra method, each spectrum matrix must have exactly two columns: x-coordinates in the first column and y-values in the second column. However, something great: the different spectra can have different lengths!\nAutomatically sorts the data\n\nExamples\n\nExample 1: resample a vector y or a matrix of ys (multiple spectra)\n\nusing Spectra, Plots\n\n# signal creation\nx = collect(0.:0.8:10.)\n# create the signals with create_peaks()\npeak_infos = [\n    Dict(:type => :gaussian, :amplitude => 10.0, :center => 4.0, :hwhm => 0.6),\n    Dict(:type => :gaussian, :amplitude => 5.0, :center => 6.0, :hwhm => 0.4),\n]\nys, y = create_peaks(x, peak_infos)\n\n# the new x axis\nx_new = collect(0.:0.05:10.)\n\n# resampling y as a vector\ny2 = resample(x, y, x_new)\n\n# resampling the ys array of the two peaks\ny3 = resample(x, ys, x_new)\n\n# plotting\np1 = scatter(x, y, label=\"Original data\")\nplot!(x_new, y2, label=\"Resampled y\")\ndisplay(p1)\n\np2 = scatter(x, ys, label=\"Original peak data\")\nplot!(x_new, y3, label=\"Resampled peaks\")\ndisplay(p2)\n\nExample 2: resampling a collection of spectra\n\nx = collect(0.:0.8:10.)\ny, ys = create_peaks(x, peak_infos)\nx2 = collect(0.:0.8:10.)\ny2, ys2 = create_peaks(x2, peak_infos)\nx3 = collect(0.:0.8:10.)\ny3, ys3 = create_peaks(x3, peak_infos)\n\nspectra_ = [[x y], [x2 y2], [x3 y3]]\nx_new = collect(0.:0.05:10.)\nspectra_resampled = resample(spectra_, x_new)\np3 = scatter(x, [y, y2, y3], label=\"Original data\")\nplot!(x_new, spectra_resampled, label=\"Resampled data\")\ndisplay(p3)\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.despiking","page":"Data Processing","title":"Spectra.despiking","text":"despiking(x::Vector{Float64}, y::Vector{Float64}; neigh::Int=4, threshold::Int=3)\ndespiking(x::Vector{Float64}, y::Matrix{Float64}; neigh::Int=4, threshold::Int=3)\ndespiking(multiple_spectra::Vector{<:Matrix{Float64}}; neigh::Int=4, threshold::Int=3)\n\nRemove spikes from signal(s) based on a threshold compared to a smoothed version.\n\nThis function smooths the spectra, calculates the residual error RMSE, and replaces points above  threshold*RMSE with the average of non-spike neighboring points.\n\nArguments\n\nx::Vector{Float64}: The x-coordinates of the signal.\ny::Union{Vector{Float64}, Matrix{Float64}}: The signal(s) to despike.\nIf y is a vector, it represents a single signal.\nIf y is a matrix, each column represents a separate signal.\nmultiple_spectra::Vector{<:Matrix{Float64}}: A collection of spectra where each spectrum is a matrix with two columns:\nFirst column: x-coordinates\nSecond column: y-values (signal intensities)\nneigh::Int=4: Number of points around each spike to consider for calculating the replacement value.\nthreshold::Int=3: Multiplier of RMSE to identify spikes (points with residuals > threshold*RMSE).\n\nReturns\n\nFor single signal input: A vector of despiked values (Vector{Float64}).\nFor multiple signals input: A matrix where each column corresponds to the despiked values of the respective input column (Matrix{Float64}).\nFor collection of spectra input: A vector of matrices, each containing the original x-coordinates and despiked y-values.\n\nMethods\n\nThis function provides three methods to handle different input types:\n\nSingle signal: despiking(x::Vector{Float64}, y::Vector{Float64}; neigh::Int=4, threshold::Int=3)\nMultiple signals with common x-axis: despiking(x::Vector{Float64}, y::Matrix{Float64}; neigh::Int=4, threshold::Int=3)\nCollection of spectra: despiking(multiple_spectra::Vector{<:Matrix{Float64}}; neigh::Int=4, threshold::Int=3)\n\nNotes\n\nThe function uses the smooth() function with the \"gcvspline\" method to create a reference smoothed signal.\nSpikes are identified as points where the residual error exceeds threshold*RMSE.\nSpike values are replaced with the mean of neighboring non-spike points.\n\nExamples\n\nExample 1: Despiking a single signal\n\nx = collect(0:0.1:10)\ny = sin.(x) + 0.1*randn(length(x))\ny[30] = 5.0 # Add a spike\ny_clean = despiking(x, y)\n\nExample 2: Despiking multiple signals with common x-axis\n\nx = collect(0:0.1:10)\ny1 = sin.(x) + 0.1randn(length(x))\ny2 = cos.(x) + 0.1randn(length(x))\ny1[30] = 5.0 # Add a spike to first signal\ny2[40] = -4.0 # Add a spike to second signal\ny_matrix = hcat(y1, y2)\ny_clean_matrix = despiking(x, y_matrix)\n\nExample 3: Despiking a collection of spectra\n\nspectrum1 = hcat(collect(0:0.1:10), sin.(collect(0:0.1:10)) + 0.1randn(101))\nspectrum1[30, 2] = 5.0 # Add a spike\nspectrum2 = hcat(collect(0:0.1:8), cos.(collect(0:0.1:8)) + 0.1randn(81))\nspectrum2[40, 2] = -4.0 # Add a spike\nspectra_collection = [spectrum1, spectrum2]\nclean_spectra = despiking(spectra_collection)\n\nErrors\n\nThrows an ArgumentError if x and y have different lengths.\nThrows an ArgumentError if neigh or threshold are not positive integers.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.tlcorrection","page":"Data Processing","title":"Spectra.tlcorrection","text":"tlcorrection(spectrum::Matrix{Float64}, temperature_C::Float64, laser_wavelength::Float64;\n             correction=\"long\", normalisation=\"area\", density=2210.0)\ntlcorrection(x::Vector{Float64}, y::Vector{Float64}, temperature_C::Float64, laser_wavelength::Float64;\n             correction=\"long\", normalisation=\"area\", density=2210.0)\ntlcorrection(multiple_spectra::Vector{<:Matrix{Float64}}, temperature_C::Float64, laser_wavelength::Float64;\n             correction=\"long\", normalisation=\"area\", density=2210.0)\n\nTemperature and laser wavelength correction for Raman spectra using one of three  available correction equations: \"long\", \"galeener\", or \"hehlen\".  Also supports optional normalization of the corrected spectra.\n\nArguments\n\nspectrum::Matrix{Float64}: A single spectrum with x (Raman shift in cm⁻¹) and y (intensity) values in the first and second columns, respectively.\nx::Vector{Float64}: The Raman shift values in cm⁻¹.\ny::Vector{Float64}: The intensity values corresponding to x.\nmultiple_spectra::Vector{<:Matrix{Float64}}: A collection of spectra where each spectrum is a matrix with two columns (x and y values).\ntemperature_C::Float64: Temperature in degrees Celsius.\nlaser_wavelength::Float64: Wavelength of the excitation laser line in nanometers (nm).\n\nOptions\n\ncorrection::String=\"long\": The equation used for the correction. Choose from:\n\"long\": Corrects using the Galeener equation with an additional ( nu_0^3 ) scaling factor for adimensionality (default).\n\"galeener\": Uses the original Galeener equation without the ( nu_0^3 ) factor.\n\"hehlen\": Applies the Hehlen equation, which includes density corrections to preserve low-frequency signals.\nnormalisation::String=\"area\": Specifies whether to normalize the corrected signal. Options are:\n\"area\": Normalizes by integrating over the area under the curve.\n\"intensity\": Normalizes by peak intensity.\n\"minmax\": Scales between minimum and maximum values.\n\"no\": No normalization (default is \"area\").\ndensity::Float64=2210.0: Density of the studied material in kg/m³, used only with the \"hehlen\" equation. Default is the density of silica glass.\n\nReturns\n\nFor single spectrum input (x and y or spectrum):\n\nx_out::Vector{Float64}: The Raman shift values (same as input x).\ny_corr::Vector{Float64}: The corrected intensity values.\nese_corr::Vector{Float64}: The propagated errors on the corrected intensities.\n\nFor multiple spectra input (multiple_spectra):\n\nA vector of tuples where each tuple contains (x_out, y_corr, ese_corr) for a single spectrum.\n\nNotes\n\nThe old API is not indicated but still available for backward compatibility: you can call tlcorrection(spectrum, ...) with spectrum = [x y]\nThis correction uses the formula reported in Galeener and Sen (1978), Mysen et al. (1982), Brooker et al. (1988) and Hehlen et al. (2010).\nThe \"galeener\" equation is the exact one reported in Galeener and Sen (1978), which is a modification from Shuker and Gammon (1970) for accounting of (vo - v)^4 dependence of the Raman intensity. See also Brooker et al. (1988) for further discussion.\nThe \"long\" equation is that of Galeener and Sen (1978) corrected by a vo^3 coefficient for removing the cubic meter dimension of the equation of \"galeener\". This equation has been used in Mysen et al. (1982) and Le Losq et al. (2012).\nThe \"hehlen\" equation is that reported in Hehlen et al. (2010). It actually originates before this publication (see Brooker et al. 1988). It uses a different correction that avoid crushing the signal below 500 cm-1. THerefore, it has the advantage of keeping intact the Boson peak signal in glasses.\n\nNotes\n\nEquations:\nThe \"long\" equation is a modified version of Galeener's equation that includes a nu_0^3 scaling factor to remove cubic meter dimensions. This version has been widely used in studies such as Mysen et al. (1982) and Le Losq et al. (2012).\nThe \"galeener\" equation is the original form reported by Galeener and Sen (1978), which modifies Shuker and Gammon's (1970) approach to account for (vo - v)^4  dependence.\nThe \"hehlen\" equation, introduced by Hehlen et al. (2010), avoids signal suppression below 500 cm⁻¹, preserving features like the Boson peak in glasses.\nError Propagation:\nErrors are calculated as sqrt{y} for raw data and propagated through the correction process.\nNormalization:\nIf normalization is enabled, it is applied after the correction step\n\nExamples\n\nExample 1: Correcting a single spectrum, provided as x-y\n\nusing Spectra, Random\nx = collect(100.0:1.0:1000)\ny = rand(length(x)) # Example spectrum\ntemperature_C = 25.0\nlaser_wavelength = 532.0 # nm\nx_out, y_corr, ese_corr = tlcorrection(x, y, temperature_C, laser_wavelength)\n\nExample 2: Correcting multiple spectra\n\nspectrum1 = hcat(collect(100.0:10:1000), rand(91))\nspectrum2 = hcat(collect(100.0:10:1000), rand(91))\nmultiple_spectra = [spectrum1, spectrum2]\ncorrected_spectra = tlcorrection(multiple_spectra, temperature_C, laser_wavelength)\n\nErrors\n\nThrows an error if an unsupported correction method is specified.\nThrows an error if normalization is not one of \"area\", \"intensity\", \"minmax\", or \"no\".\nThrows an error if input spectra have fewer than two columns or if no spectra are provided for multiple-spectra input.\n\nReferences\n\nBrooker et al. (1988) Journal of Raman Spectroscopy 19(2), 71-78.\nGaleener and Sen (1978) Physical Review B 17 (4): 1928–33.\nHehlen (2010) Journal of Physics: Condensed Matter 22 (2): 025401.\nLe Losq et al. (2012) American Mineralogist, 97, 779–790.\nMysen et al. (1982) American Mineralogist 67: 686–95.\nShuker and Gammon (1970) Physical Review Letters 25 (4): 222–25.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.normalise","page":"Data Processing","title":"Spectra.normalise","text":"normalise(y::Union{Vector{Float64}, Matrix{Float64}}; x::Union{Vector{Float64}, Nothing}=nothing, method::String=\"intensity\")\n\nNormalise the y signal(s) using one of several methods.\n\nArguments\n\ny::Union{Vector{Float64}, Matrix{Float64}}: The input signal(s) to normalize.\nIf y is a vector, it represents a single signal.\nIf y is a matrix, each column represents a separate signal.\nx::Union{Vector{Float64}, Nothing}: The x-coordinates corresponding to the y values (used only for \"area\" normalization). Default is nothing.\nmethod::String: The normalization method to use. Options are:\n\"area\": Normalize by the area under the curve (requires x).\n\"intensity\": Normalize by dividing by the maximum intensity.\n\"minmax\": Normalize to the range [0, 1].\n\nReturns\n\nA normalized vector or matrix of signals (Vector{Float64} or Matrix{Float64}).\n\nNotes\n\nFor \"area\" normalization, you must provide an x vector with the same length as each column of y.\nIf using \"intensity\" or \"minmax\", no x vector is required.\n\nExamples\n\nusing Spectra, Plots\n\n# Single signal normalization\n\nx = collect(0.:0.1:10.)\n\n# create a signal that is the combination of two gaussian peaks\ny, ys = gaussiennes([10.,5.], [5.,6.], [1.,0.1], x)\n\n# normalise the signal by area\ny_norm = normalise(y; x=x, method=\"area\")\nplot(x, y_norm)\n\n# Or normalise multiple signals, such as the two peaks created above (no need of the x axis in this case):\n\npeaks_norm = normalise(ys, method=\"intensity\")\nplot(x, y_norm)\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.extract_signal","page":"Data Processing","title":"Spectra.extract_signal","text":"extract_signal(x::Vector{Float64}, y::Vector{Float64}, roi::Matrix{Float64}) -> Tuple{Vector{Float64}, Vector{Float64}, Vector{Int}}\nextract_signal(spectrum::Matrix{Float64}, roi::Matrix{Float64})\nextract_signal(multiple_spectra::Vector{<:Matrix{Float64}}, roi::Matrix{Float64})\n\nExtract the x-y spectral values in specified regions of interest (ROI) and their indices.\n\nYou can pass associated x and y values, a single spectrum in the form of a [x y] matrix, or a list of [x y] matrices.\n\nArguments\n\nx::Vector{Float64}: The x-axis values.\ny::Vector{Float64}: The corresponding y-axis values.\nspectrum::Matrix{Float64}: A matrix of size n x 2, where:\nColumn 1: x-axis values.\nColumn 2: y-axis values.\nmultiple_spectra::Vector{<:Matrix{Float64}}: A collection of spectra, where each spectrum is a matrix with two columns:\nFirst column: x-coordinates\nSecond column: y-values (signal intensities)\nroi::Matrix{Float64}: A matrix of size n x 2, where each row specifies a region of interest:\nColumn 1: Lower bounds of the ROI.\nColumn 2: Upper bounds of the ROI.\n\nReturns\n\nif calling extract_signal(x, y, roi), it returns a tuple containing:\nVector{Float64}: The x values within the ROI.\nVector{Float64}: The y values within the ROI.\nVector{Int}: The indices of the x and y values within the ROI.\nif calling extract_signal(spectrum, roi), it returns a tuple containing:\nVector{Float64}: The x values within the ROI.\nVector{Float64}: The y values within the ROI.\nVector{Int}: The indices of the x and y values within the ROI.\nif calling extract_signal(multiple_spectra, roi), it returns a vector of tuples, where each tuple corresponds to a spectrum and contains:\nVector{Float64}: The x values within the ROI.\nVector{Float64}: The y values within the ROI.\nVector{Int}: The indices of the x and y values within the ROI.\n\nErrors\n\nThrows an error if x and y have different lengths.\nThrows an error if roi is not a 2D matrix with exactly 2 columns.\n\nNotes\n\nThe function sorts both x-y pairs and the ROI for safety before processing.\nMultiple ROIs are supported, and their results are concatenated.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.baseline","page":"Data Processing","title":"Spectra.baseline","text":"baseline(x_input::Vector{Float64}, y_input::Vector{Float64}; roi::Union{Matrix{Float64}, Nothing} = nothing, method::String = \"polynomial\", kwargs...)\nbaseline(x_input::Vector{Float64}, y_input::Matrix{Float64}; roi::Union{Matrix{Float64}, Nothing} = nothing,  method::String = \"polynomial\", kwargs...)\nbaseline(multiple_spectra::Vector{<:Matrix{Float64}}; roi::Union{Matrix{Float64}, Nothing} = nothing,  method::String = \"polynomial\", kwargs...)\n\nSubtract a baseline from a spectrum y sampled at x values, or a set of spectra, using specified methods  that can either fit regions of interests (roi) defined by the user, or use automatic algorithms.\n\nArguments\n\nx_input::Vector{Float64}: The x-axis values (e.g., wavelengths or time points).\ny_input::Union{Vector{Float64}, Matrix{Float64}}: The spectral data to correct. Can be a single spectrum (vector) or multiple spectra (matrix).\nmultiple_spectra::Vector{<:Matrix{Float64}}: A collection of spectra, where each spectrum is a matrix with two columns:\nFirst column: x-coordinates\nSecond column: y-values (signal intensities)\nroi::Union{Matrix{Float64}, Nothing}: Regions of interest for baseline fitting, specified as a matrix where each row defines a range [start, end]. Default is nothing.\nmethod::String: The baseline fitting method. Default is \"polynomial\". Supported methods:\n\"polynomial\" or \"poly\": Polynomial fitting.\n\"Dspline\": 1D spline fitting using Dierckx library.\n\"gcvspline\": Generalized Cross Validation Spline fitting.\n\"exp\": Exponential background fitting.\n\"log\": Logarithmic background fitting.\n\"rubberband\": Rubberband baseline fitting.\n\"als\": Asymmetric least squares baseline fitting.\n\"arPLS\": Asymmetrically reweighted penalized least squares fitting.\n\"drPLS\": Doubly reweighted penalized least squares fitting.\n\nKeyword Arguments\n\nOptional parameters for specific methods:\n\npolynomial_order::Int: Degree of polynomial for polynomial fitting. Default is 1.\ns::Float64: Smoothing coefficient for spline methods. Default is 2.0.\nlambda::Float64: Smoothness parameter for ALS, arPLS, drPLS, and Whittaker methods.\np::Float64: Parameter for ALS algorithm. Default is 0.01.\nratio::Float64: Parameter for arPLS and drPLS algorithms. Default is 0.01.\nniter::Int: Number of iterations for ALS and drPLS algorithms. Default is 10.\neta::Float64: Roughness parameter for drPLS algorithm. Default is 0.5.\nd::Int: Order of differences for smoothing algorithms. Default is 2.\nd_gcv::Int: Order of differences for GCV spline algorithm. Default is 3.\np0_exp::Vector{Float64}: Initial parameters for exponential fitting. Default is [1., 1., 1.].\np0_log::Vector{Float64}: Initial parameters for logarithmic fitting. Default is [1., 1., 1., 1.].\n\nReturns\n\ncorrected_signal::Union{Vector{Float64}, Matrix{Float64}}: Baseline-corrected signal(s).\nbaseline::Union{Vector{Float64}, Matrix{Float64}}: Calculated baseline(s).\n\nnote: Note\nIf providing a collection of spectra, you will receive a collection of tuples (corrected_signal, baseline)\n\nExamples\n\nCorrecting a single spectrum:\n\nx = collect(50:1.0:500)\nbackground = 10.0 .* sin.(x./50.0) + 0.1.*x\ny = 50.0 .* exp.(-log(2) .* ((x .-250.0)./1.0).^2) + background\ny_corrected, y_baseline = baseline(x, y, method=\"drPLS\")\n\nCorrecting with regions of interest, GCV spline method:\n\nroi = [[50.0, 200.0], [300.0, 500.0]]\ny_corrected, y_baseline = baseline(x, y, roi=roi, method=\"gcvspline\")\n\nYou can also adjust manually the smoothing spline coefficient s:\n\ny_corrected, y_baseline = baseline(x, y, roi=roi, method=\"gcvspline\", s=1.0)\n\nUsing a vector or arrays of y values:\n\nusing Spectra, Plots\n\n# we create a fake signal with 2 peaks plus 2 backgrounds\nx = collect(0.:0.2:10.)\n\n# create the signals with create_peaks()\npeak_infos = [\n    Dict(:type => :gaussian, :amplitude => 10.0, :center => 4.0, :hwhm => 0.6),\n    Dict(:type => :gaussian, :amplitude => 5.0, :center => 6.0, :hwhm => 0.4),\n]\nys, _ = create_peaks(x, peak_infos)\n\n# add backgrounds\nys[:,1] = ys[:,1] .+ 0.1 * x\nys[:,2] = ys[:,2] .+ 0.2 * x\n\n# fit the background on the first peak: provide as a vector\ny_corr, base_ = baseline(x, ys[:,1], method=\"als\")\np1 = plot(x, ys[:,1])\nplot!(x, base_)\ndisplay(p1)\n\n# Fit the background on multiple peaks: just provide the array!\ny_corr, base_ = baseline(x, ys, method=\"als\")\np2 = plot(x, ys, label=[\"signal 1\" \"signal 2\"])\nplot!(x, base_, label=[\"background 1\" \"background 2\"])\ndisplay(p2)\n````\n## Treating a collection of y values:\n\nGiven x1, y1 and x2, y2 two signals, we can create a collection of spectra\nand pass it to baseline():\n\njulia collectionsp = [[x1 y1], [x2 y2]] collectedbaselines = baseline(collectionsp, method=\"als) ```Thecollectedbaselines` is then a vector that contains tuples of (y_corrected, baseline).\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.als_baseline","page":"Data Processing","title":"Spectra.als_baseline","text":"als_baseline(x::Vector{Float64}, y::Vector{Float64}; lambda::Float64=1.0e5, p::Float64=0.01, niter::Int=50, d::Int=2) -> Vector{Float64}\n\nEstimate the baseline of a signal using the Asymmetric Least Squares (ALS) method.\n\nArguments\n\nx::Vector{Float64}: The x-axis values (must be increasing).\ny::Vector{Float64}: The corresponding y-axis values.\nlambda::Float64=1.0e5: Smoothing parameter; larger values result in smoother baselines.\np::Float64=0.01: Asymmetry parameter; typically between 0.001 and 0.1.\nniter::Int=50: Number of iterations for the algorithm.\nd::Int=2: Order of differences for the penalty term.\n\nReturns\n\nz::Vector{Float64}: The estimated baseline.\n\nnote: Note\nThis method uses an iterative approach to minimize the asymmetric least squares error, making it suitable for signals with varying background intensity.\n\nReferences\n\nG. Eilers and H. Boelens, \"Baseline correction with asymmetric least squares smoothing\" 2005.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.arPLS_baseline","page":"Data Processing","title":"Spectra.arPLS_baseline","text":"arPLS_baseline(x::Vector{Float64}, y::Vector{Float64}; lambda::Float64=1.0e5, ratio::Float64=0.01, d::Int=2) -> Vector{Float64}\n\nEstimate the baseline of a signal using the Adaptive Reweighted Penalized Least Squares (arPLS) method.\n\nArguments\n\nx::Vector{Float64}: The x-axis values (must be increasing).\ny::Vector{Float64}: The corresponding y-axis values.\nlambda::Float64=1.0e5: Smoothing parameter; larger values result in smoother baselines.\nratio::Float64=0.01: Convergence ratio for stopping criterion.\nd::Int=2: Order of differences for the penalty term.\n\nReturns\n\nz::Vector{Float64}: The estimated baseline.\n\nNotes\n\nThe arPLS algorithm iteratively adjusts weights based on residuals to improve baseline estimation accuracy.\n\nReferences\n\nBaek et al., \"Baseline correction using adaptive iteratively reweighted penalized least squares,\" Analyst 140 (2015): 250–257.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.drPLS_baseline","page":"Data Processing","title":"Spectra.drPLS_baseline","text":"drPLS_baseline(x::Vector{Float64}, y::Vector{Float64}; lambda::Float64=1.0e5, niter::Int=50, eta::Float64=0.5, ratio::Float64=0.001, d::Int=2) -> Vector{Float64}\n\nPerform baseline correction using the Doubly Reweighted Penalized Least Squares (drPLS) algorithm.\n\nArguments\n\nx::Vector{Float64}: The x-axis values (must be increasing).\ny::Vector{Float64}: The corresponding y-axis values.\nlambda::Float64=1.0e5: Smoothing parameter; larger values result in smoother baselines.\nniter::Int=50: Maximum number of iterations for the algorithm.\neta::Float64=0.5: Parameter controlling the influence of weights in the penalty term.\nratio::Float64=0.001: Convergence threshold for stopping criterion.\nd::Int=2: Order of differences for the penalty term.\n\nReturns\n\nbaseline_fitted::Vector{Float64}: The estimated baseline.\n\nNotes\n\nThe drPLS algorithm builds on arPLS by introducing an additional reweighting scheme to improve robustness against noise and outliers.\n\nReferences\n\nXu et al., \"Baseline correction method based on doubly reweighted penalized least squares,\" Applied Optics 58 (2019): 3913–3920.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.rubberband_baseline","page":"Data Processing","title":"Spectra.rubberband_baseline","text":"rubberband_baseline(x::Vector{Float64}, y::Vector{Float64}; segments=1) -> Vector{Float64}\n\nEstimate a baseline using the rubberband method based on the lower convex hull.\n\nwarning: Warning\nThis function is currently under development and may not behave as intended in all cases. !!\n\nArguments\n\nx::Vector{Float64}: The x-axis values of the data.\ny::Vector{Float64}: The corresponding y-axis values.\nsegments (optional): Specifies how to segment the data:\nIf an integer, splits the data into equally sized segments (default is 1).\nIf a vector of integers, specifies exact indices where segmentation occurs.\n\nReturns\n\nbaseline_fitted::Vector{Float64}: The estimated baseline as a lower envelope of the data.\n\nRaises\n\nThrows an error if x and y have different lengths.\nThrows an error if a segment does not contain enough points for interpolation.\n\nNotes\n\nThe rubberband method estimates a baseline by:\n\nIdentifying local minima to approximate the lower envelope.\nComputing the convex hull of these points.\nInterpolating between convex hull points to generate a smooth baseline.\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.smooth","page":"Data Processing","title":"Spectra.smooth","text":"smooth(x::Vector{Float64}, y::Union{Vector{Float64}, Matrix{Float64}}; \n       method::String = \"gcvspline\", \n       window_length::Int = 5, \n       polyorder::Int = 2, \n       lambda::Float64 = 10.0^5, \n       d::Int = 2, \n       w = nothing, \n       d_gcv::Int = 3)\n\nSmooth a signal using various smoothing methods.\n\nArguments\n\nx::Vector{Float64}: The x-coordinates of the input signal (e.g., time or spatial values).\ny::Union{Vector{Float64}, Matrix{Float64}}: The y-coordinates of the input signal to be smoothed.\nmethod::String: The smoothing method to use. Options include:\n\"whittaker\": Whittaker smoother, which uses weights (w) and smoothing parameter (lambda).\n\"gcvspline\": Generalized cross-validation spline smoothing (requires DataInterpolations.jl).\n\"flat\": Moving average.\n\"hanning\", \"hamming\", \"bartlett\", \"blackman\": Window-based smoothing methods (requires DSP.jl).\n\"savgol\": Savitzky-Golay filter.\nwindow_length::Int: The length of the smoothing window (used in window-based and Savitzky-Golay methods). Must be a positive odd integer\npolyorder::Int: The polynomial order for the Savitzky-Golay filter. Must be less than window_length\nlambda::Float64: Smoothing parameter for the Whittaker smoother. Higher values result in smoother fits\nd::Int: Order of differences for the Whittaker smoother. Default is 2.\nw: Weights for the Whittaker smoother. size(w) should be equal to size(y). If not provided (nothing), uniform weights are used by default.\nd_gcv::Int: Order of differences for the GCV spline algorithm (used in \"gcvspline\")\n\nReturns\n\nA smoothed vector or matrix of signals (Vector{Float64} or Matrix{Float64}).\n\nNotes\n\nDeprecated Methods: The methods \"GCVSmoothedNSpline\", \"MSESmoothedNSpline\", and \"DOFSmoothedNSpline\" are no longer supported and will throw an error if used.\nFor window-based methods (\"flat\", \"hanning\", etc.), the signal is symmetrically extended at both ends to reduce edge effects.\nThe Savitzky-Golay filter requires that window_length be a positive odd integer and that polyorder be less than window_length.\nFor Whittaker smoothing, if weights (w) are provided, they must have the same length as x.\n\nExample\n\nusing Spectra, Plots\n\nx = collect(1:10)\ny = [1.0, 2.5, 3.0, 4.2, 5.1, 6.0, 7.3, 8.1, 9.4, 10.0]\nmethod = \"hanning\"\nwindow_length = 3\n\nsmoothed_y = smooth(x, y; method=method, window_length=window_length)\np1 = plot(x, [y smoothed_y], label=[\"Original\" \"Smoothed\"], title=\"Smoothing Example\", xlabel=\"X-axis\", ylabel=\"Y-axis\")\ndisplay(p1)\n\nErrors\n\nThrows an error if an unsupported or deprecated method is specified.\nThrows an error if window_length is not a positive odd integer.\nFor Savitzky-Golay smoothing:\nThrows an error if polyorder is greater than or equal to window_length.\nFor Whittaker smoothing:\nThrows an error if weights (w) are provided but do not match the length of x.\n\nReferences\n\nFor Window-based filtering,see DSP.jl documentation: https://docs.juliadsp.org/stable/windows/\n\n\n\n\n\n","category":"function"},{"location":"PreProcessing.html#Spectra.whittaker","page":"Data Processing","title":"Spectra.whittaker","text":"whittaker(x::Vector{Float64}, y::Vector{Float64}, w::Vector{Float64}, lambda::Float64; d::Int=2) -> Vector{Float64}\n\nSmooth a signal using the Whittaker smoother with divided differences.\n\nArguments\n\nx::Vector{Float64}: The x-axis values of the data (must be increasing).\ny::Vector{Float64}: The corresponding y-axis values, assumed to be sampled at equal intervals.\nw::Vector{Float64}: Weights for each data point. Higher weights indicate greater importance in smoothing.\nlambda::Float64: Smoothing parameter; larger values result in smoother outputs. It is recommended to be set based on the length of x.\nd::Int=2: Order of differences for the penalty term (default is 2).\n\nReturns\n\nz::Vector{Float64}: The smoothed y-axis values.\n\nNotes\n\nFor equally spaced x values, higher-order differences are computed manually.\nFor unequally spaced x values, a difference matrix is constructed using the ddmat function.\nA sparse matrix representation is used for computational efficiency.\n\nReferences\n\nEilers, P.H.C. (2003). \"A perfect smoother.\" Analytical Chemistry, 75, 3631–3636.\n\nExample\n\nusing Spectra, Random, Plots\nx = sort(rand(50) .* 10)                 # Randomly spaced x values in [0, 10]\ntrue_y = sin.(x)\ny = true_y .+ 0.1 .* randn(length(x))  # Noisy sine wave\nw = ones(length(x))                     # Equal weights\nlambda = 0.1                          # Smoothing parameter, !!! its value depends on the length of x !!!\nz = whittaker(x, y, w, lambda; d=2)\n\np1 = plot(x, true_y); plot!(x, y); plot!(x, z), display(p1)\n\nMatlab version by Paul Eilers, 2003 Julia translation by Charles Le Losq 2017, revised 2025\n\n\n\n\n\n","category":"function"},{"location":"Tips.html#Tips","page":"Tips","title":"Tips","text":"","category":"section"},{"location":"Tips.html","page":"Tips","title":"Tips","text":"In this section are listed various tips for the use of Julia and Spectra:","category":"page"},{"location":"Tips.html#Installation","page":"Tips","title":"Installation","text":"","category":"section"},{"location":"Tips.html","page":"Tips","title":"Tips","text":"If you see errors messages linked to PyCall, you may have a problem with your environment variable. To solve it, type the following commands in the Julia prompt:","category":"page"},{"location":"Tips.html","page":"Tips","title":"Tips","text":"```julia-repl\njulia> ENV[\"PYTHON\"]=\"\"\njulia> Using Pkg\njulia> Pkg.build(\"PyCall\")\n```","category":"page"},{"location":"Tips.html","page":"Tips","title":"Tips","text":"At this point it should work. If yes, you now can type ']' in the Julia repl and then enter: \tjulia-repl \tpkg> add Spectra","category":"page"},{"location":"Tips.html#Maintenance","page":"Tips","title":"Maintenance","text":"","category":"section"},{"location":"Tips.html","page":"Tips","title":"Tips","text":"The Julia package ecosystem is frequently evolving. Because of that, it is recommended to update frequently. Type ']' in the Julia repl and then enter: \tjulia-repl \tpkg> update","category":"page"},{"location":"Tips.html#Running-Spectra","page":"Tips","title":"Running Spectra","text":"","category":"section"},{"location":"Tips.html","page":"Tips","title":"Tips","text":"Always be careful to variable types. Functions will return an error message if you do not enter the good type.","category":"page"},{"location":"Measurements.html#Measurements","page":"Measurements","title":"Measurements","text":"","category":"section"},{"location":"Measurements.html#Introduction","page":"Measurements","title":"Introduction","text":"","category":"section"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"Various functions to measure the parameters of peaks visible on spectra are available.","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"A new core function is introduced in v1.1: find_peaks, which leverages the Peaks.jl package. This function allows you to, as its name says, find peaks in a signal and calculate various parameters, such as their heights, widths, centroids... The later calculation relies on the centroid function, which can be called independently.","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"Finally, earlier versions of Spectra had a peakmeas function to measure various parameters (height, width, centroid...). It works but please use find_peaks in your futur codes, it is much better. peakmeas will be removed in a future release of Spectra.","category":"page"},{"location":"Measurements.html#Example","page":"Measurements","title":"Example","text":"","category":"section"},{"location":"Measurements.html#Example-signal","page":"Measurements","title":"Example signal","text":"","category":"section"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"We first generate a dummy signal to play with:","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"using Plots, Spectra, Random\n\n# the x axis\nx = collect(0:0.1:100)\n\n# a fake signal: perfect y\ny_perfect = gaussian(x, 1.0, 50.0, 6.0)\n\n# we add noise: observed y\ny = y_perfect + 0.05*randn(size(x,1))\n\nplot(x, y, label=\"Noisy observed signal\", xlabel=\"X\", ylabel=\"Y\")\nsavefig(\"ppm_1.svg\"); nothing #hide","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"(Image: )","category":"page"},{"location":"Measurements.html#Estimating-parameters-for-one-peak","page":"Measurements","title":"Estimating parameters for one peak","text":"","category":"section"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"For one peak, estimations can be done using peakmeas:","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"height_y, hwhm_y, position_y, centroid_y, smoothed_y = peakmeas(x,vec(y),smoothing = \"yes\", method= \"savgol\",  y_smo_out = true)\n\nprintln(\"Estimated peak height is $(height_y)\")\nprintln(\"Estimated peak hwhm is $(hwhm_y)\")\nprintln(\"Estimated peak position is $(position_y)\")\nprintln(\"Estimated peak centroid is $(centroid_y)\")","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"warning: Warning\npeakmeas is basic. It does not work on multiple peaks. Prefer using find_peaks.","category":"page"},{"location":"Measurements.html#Find-and-measure-multiple-peaks","page":"Measurements","title":"Find and measure multiple peaks","text":"","category":"section"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"To find and measure parameters of a peak or multiple peaks in a signal, we can use find_peaks:","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"result = find_peaks(x, y, smoothing=false, method=\"gcvspline\", window_size = 20)\nprintln(\"Peak positions: \", result.peak_positions)\nprintln(\"Peak heights: \", result.peak_heights)\nprintln(\"Peak hwhms: \", result.peak_hwhms)\nprintln(\"Peak centroids: \", result.peak_centroids)\nresult.plot_peaks\nsavefig(result.plot_peaks, \"ppm_2.svg\"); nothing #hide","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"(Image: )","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"Hum... it finds too much peaks here. We need to tweak the parameters of the find_peaks function.  We can increase the min_height value to detect only peaks above a certain threshold.  We can also smooth the signal, it will help filter the noise. Other options are possible, see the specific documentation of find_peaks.","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"result = find_peaks(x, y, smoothing=true, method=\"gcvspline\", window_size = 20, min_height=0.2)\nprintln(\"Peak positions: \", result.peak_positions)\nprintln(\"Peak heights: \", result.peak_heights)\nprintln(\"Peak hwhms: \", result.peak_hwhms)\nprintln(\"Peak centroids: \", result.peak_centroids)\nresult.plot_peaks\nsavefig(result.plot_peaks, \"ppm_3.svg\"); nothing #hide","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"(Image: )","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"Good! It works now better.","category":"page"},{"location":"Measurements.html#Peak-centroid","page":"Measurements","title":"Peak centroid","text":"","category":"section"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"The centroid  of a peak or of a signal can also be measured using directly the centroid function.  It accepts x-y inputs, list of x-y spectra, or arrays of ys spectra associated to a vector of x values, see the documentation of centroid[@ref].","category":"page"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"centroid2 = centroid(x,y)\nprintln(\"Estimated peak centroid is $(centroid2)\")","category":"page"},{"location":"Measurements.html#Functions-API","page":"Measurements","title":"Functions API","text":"","category":"section"},{"location":"Measurements.html","page":"Measurements","title":"Measurements","text":"find_peaks\ncentroid\npeakmeas","category":"page"},{"location":"Measurements.html#Spectra.find_peaks","page":"Measurements","title":"Spectra.find_peaks","text":"find_peaks(\nx::Vector{Float64}, \ny::Vector{Float64};\nsmoothing::Bool = false,\nwindow_size::Int = 20,\nmin_height::Float64 = 0., max_height::Float64 = Inf,\nmin_prom::Float64 = 0., max_prom::Float64 = Inf,\nmin_width::Float64 = 0., max_width::Float64 = Inf, relwidth::Float64 = 0.5,\nkwargs...\n)\n\nIdentify peaks in spectral data (x, y) based on specified criteria such as height, prominence, and width. \n\nIt optionally applies smoothing to the signal before peak detection.\n\nArguments\n\nx::Vector{Float64}: The x-axis values (e.g., wavelengths or time points).\ny::Vector{Float64}: The y-axis values (e.g., intensities).\nsmoothing::Bool: Whether to apply smoothing to the signal before peak detection. Default is false.\nwindow_size::Int: Size of the window for peak detection (in indices). Default is 20.\nmin_height::Float64: Minimum height of peaks to consider. Default is 0.0.\nmax_height::Float64: Maximum height of peaks to consider. Default is 100.0.\nmin_prom::Float64: Minimum prominence of peaks to consider. Default is 0.0.\nmax_prom::Float64: Maximum prominence of peaks to consider. Default is infinity (Inf).\nmin_width::Float64: Minimum width of peaks to consider (in indices). Default is 0.0.\nmax_width::Float64: Maximum width of peaks to consider (in indices). Default is infinity (Inf).\nrelwidth::Float64: Relative width parameter for peak widths. Default is 0.5.\nAdditional keyword arguments (kwargs...) are passed to the smoothing function if smoothing is enabled.\n\nReturns\n\nA named tuple containing:\n\npeak_positions::Vector{Float64}: X positions of detected peaks.\npeak_heights::Vector{Float64}: Heights of detected peaks.\npeak_prominences::Vector{Float64}: Prominences of detected peaks.\npeak_hwhms::Vector{Float64}: Half-width at half maximum values for detected peaks.\npeak_centroids::Vector{Float64}: Centroid positions for detected peaks.\nA plot object showing the detected peaks (plot_peaks), using the recipe from the Peaks.jl package.\n\nExamples\n\nExample 1: Basic peak detection\n\nx = collect(1:1.0:100)\ny = gaussian(x, 1.0, 30.0, 3.0) + lorentzian(x, 1.0, 60.0, 6.0) + 0.01*randn(length(x))\n\nresult = find_peaks(x, y; smoothing=false, window_size=10, min_height=0.2)\n\nprintln(\"Peak positions: \", result.peak_positions)\nprintln(\"Peak heights: \", result.peak_heights)\ndisplay(result.plot_peaks)\n\nExample 2: Peak detection with gcvspline smoothing\n\nx = collect(1:1.0:100)\ny = gaussian(x, 1.0, 30.0, 3.0) + lorentzian(x, 1.0, 60.0, 6.0) + 0.01*randn(length(x))\n\nresult = find_peaks(x, y; smoothing=true, method=\"gcvspline\", window_size=10, min_height=0.2)\n\nprintln(\"Peak positions: \", result.peak_positions)\nprintln(\"Peak heights: \", result.peak_heights)\ndisplay(result.plot_peaks)\n\nNotes\n\nthis function is a convenient wrapper around the Peaks.jl functionalities to find peaks in a vector y. For more control, you can directly use the Peaks.jl functions, the package should be available in your environment as it is a dependency for Spectra!\nfor smoothing, try the method = \"gcvspline\" or method = \"savgol\" options, which are the most efficient for peak detection.\nthe window_size parameter is not in the units of x, but in the units of index. For example, if you have 1000 points in your x-axis and you want to detect peaks with a window of 10 points, set window_size=10.\nthe min_width and max_width parameters are also not in the units of x, but in the units of index. For example, if you have 1000 points in your x-axis and you want to detect peaks with a width of 10 points, set min_width=10 and max_width=10.\nthe relwidth parameter is a relative width parameter for peak widths. It is used to calculate the width of the peak at a certain relative height. For example, if you set relwidth=0.5, it will calculate the width of the peak at half its maximum height.\n\n\n\n\n\n","category":"function"},{"location":"Measurements.html#Spectra.centroid","page":"Measurements","title":"Spectra.centroid","text":"centroid(x::Vector{Float64}, y::Vector{Float64}; smoothing::Bool = false, kwargs...)\ncentroid(spectrum::Matrix{Float64}; smoothing::Bool = false, kwargs...)\ncentroid(x::Vector{Float64}, y::Matrix{Float64}; smoothing::Bool = false, kwargs...)\ncentroid(spectra::Vector{<:Matrix}; smoothing::Bool = false, kwargs...)\n\nCalculate the centroid of a spectrum or a set of spectra.\n\nThe function supports optional smoothing and handles various input formats, including single spectra, matrices, and lists of spectra.\n\nMethods\n\ncentroid(x::Vector{Float64}, y::Vector{Float64}; smoothing::Bool = false, kwargs...) Computes the centroid for a single spectrum.\ncentroid(spectrum::Matrix{Float64}; smoothing::Bool = false, kwargs...) Computes the centroid for a two-column matrix where the first column represents x values and the second column represents y values.\ncentroid(x::Vector{Float64}, y::Matrix{Float64}; smoothing::Bool = false, kwargs...) Computes the centroid for multiple spectra stored as columns in a matrix.\ncentroid(spectra::Vector{<:Matrix}; smoothing::Bool = false, kwargs...) Computes the centroids for a list of x-y spectra.\n\nArguments\n\nx::Vector{Float64}: The x-axis values (e.g., wavelengths or time points).\ny::Union{Vector{Float64}, Matrix{Float64}}: The y-axis values (e.g., intensities), either as a single vector or multiple columns (for multiple spectra).\nspectrum::Matrix{Float64}: A two-column matrix with x values in the first column and y values in the second column.\nspectra::Vector{<:Matrix}: A list of matrices, each representing an x-y spectrum.\nsmoothing::Bool: Whether to apply smoothing to the y-axis values before calculating the centroid. Default is false.\nkwargs...: Additional keyword arguments passed to the smoothing function if smoothing is enabled.\n\nReturns\n\nFor single spectrum (x, y): A scalar value representing the centroid position.\nFor multiple spectra (x, y as matrix): A vector where each element is the centroid of a corresponding column in y.\nFor two-column spectrum (spectrum): A scalar value representing the centroid position.\nFor list of spectra (spectra): A vector where each element is the centroid of a corresponding spectrum in the list.\n\nExamples\n\nExample 1: Centroid of a single spectrum\n\nx = collect(0.:1.:100.)\ny_peak = gaussian(x, 1., 50., 10.)\ncentroid_peak = centroid(x, y_peak)\n\nExample 2: Centroid of a single spectrum with smoothing\n\nx = collect(0.:1.:100.)\ny_peak = gaussian(x, 1., 50., 10.)\ncentroid_peak = centroid(x, y_peak, smoothing=true, method=\"gcvspline\")\n\nExample 3: Centroid of a single spectrum as an array\n\nmy_spectrum = [x y_peak]\ncentroid_peak = centroid(my_spectrum)\n\nExample 4: Centroids of an array of y spectra\n\nys = [y_peak y_peak y_peak y_peak]\ncentroid_peaks = centroid(x, ys)\n\nExample 5: Centroids of a vector of x-y spectra\n\nvector_spectra = [[x y_peak], [x y_peak], [x y_peak]]\ncentroid_peaks = centroid(vector_spectra)\n\nNotes\n\nThe optional smoothing operation uses an external function (smooth) and accepts additional parameters via kwargs....\nEnsure that input dimensions are consistent (e.g., matching lengths for x and y, or proper formatting for matrices).\n\n\n\n\n\n","category":"function"},{"location":"Measurements.html#Spectra.peakmeas","page":"Measurements","title":"Spectra.peakmeas","text":"peakmeas(x::Array{Float64,1}, y::Array{Float64,1}; smoothing::Bool = true, method::String = \"savgol\", window_length::Int=5, polyorder::Int=2, ese_y::Float64=1., y_smo_out::Bool=false)\n\nPerform measurements of the position, width, intensity and centroid of a dominant peak in a provided x-y signal.\n\nIt smooths the signal with a Savitzky-Golay filter prior to measuring the peak position,  width and intensity. It is advised to check that the M and N values of the Savitzky-Golay  filter are adequate for your problem before trusting the results from peakmeas. For that, set y_smo_out=true.\n\nHalf-width at half-maximum are calculated as the width of the peak at half its maximum intensity. This calculation is not affected by any asumption of peak symmetry (no fitting is done).\n\nCentroïd is calculated as sum(y./sum(y).*x).\n\nwarning: Warning\nThis function may not stay in future versions. Consider using find_peaks instead.\n\nInputs\n\n-x::Array{Float64}: the x values -y::Array{Float64}: the y values\n\nOptions\n\n-smoothing::String: triggers the smoothing of the spectrum if set to yes (default value); -filter::Symbol: the filter that will be used. See the smooth function documentation; -M::Int: M parameter for smoothing y with a Savitzky-Golay filter. See smooth function documentation. Default = 5. -N::Int: N parameter for smoothing y with a Savitzky-Golay filter. See smooth function documentation. Default = 2.  -y_smo_out::bool: Outputs the smoothed signal.\n\nOutputs\n\n-intensity::Float64: peak intensity -position::Float64: peak position -hwhm: Float6:: peak half-width at half-maximum -centroïd::Float64: peak centroid\n\n\n\n\n\n","category":"function"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"The source files for all examples can be found in /examples.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"EditURL = \"../../../examples/Raman_spectrum_fitting.jl\"","category":"page"},{"location":"examples/Raman_spectrum_fitting.html#Peak-fitting-the-Raman-spectrum-of-a-glass","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"","category":"section"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Code by Charles Le Losq, Created 7 April 2015 for Python, Modified 30 Sept. 2016 for Julia, updated February 2019, then April 2025.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Last modified: April 2025 for release of Spectra v2.0.0.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Glass materials usually present broad bands due to their inherent structural disorder. Due to this, peak-fitting Raman spectra of glasses is informative but difficult, and requires a careful balance between model freedom and constraints. Using boundaries for parameters can help, as well as setting priors on model parameters and working in a Bayesian framework. Spectra provides a function to do such things, fit_peaks.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Here, we will fit a Raman spectrum of a glass with Julia, using the fit_peaks function now available in Spectra. We will leverage the quasi-Newton method, with a loss function that takes into account data and prior model errors. In other terms, we are setting ourselves in a Bayesian framework, with priors on the model parameters.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"You could solve the following problem in a pure Bayesian approach, using e.g. HMC algorithm in Turing.jl. However, it takes some time... The quasi-Newton method is clean, the Julia code is the direct transcription of the mathematical formulas available in Tarantola (2005), chapter 3. This method is fast, accurate, but sometimes a bit instable. You can also use the Interior Point Newton algorithm from Optim.jl, by setting the backend to :Optim. It is good, stable but slightly slower. It also benefits from boundaries!","category":"page"},{"location":"examples/Raman_spectrum_fitting.html#Context","page":"Peak fitting the Raman spectrum of a glass","title":"Context","text":"","category":"section"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"In this example, we fit the 850-1300 cm^-1 portion of a Raman spectrum of a lithium tetrasilicate glass Li_2Si_4O_9, the name will be abbreviated LS4 in the following.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"For further references for fitting Raman spectra of glasses, please see for instance:","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Virgo et al., 1980, Science 208, p 1371-1373;\nMysen et al., 1982, American Mineralogist 67, p 686-695;\nMcMillan, 1984, American Mineralogist 69, p 622-644; Mysen, 1990, American Mineralogist 75, p 120-134;\nLe Losq et al., 2014, Geochimica et Cosmochimica Acta 126, p 495-517\nLe Losq et al., 2015, Progress in Earth and Planetary Sciences 2:22.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"fit_peaks is meant to fit a single spectrum. You could do a loop to fit several spectra, but if you want to define global models, I invite you to use the JuMP framework or, if you fancy Bayesian MCMC methods, Turing.jl","category":"page"},{"location":"examples/Raman_spectrum_fitting.html#Importing-libraries-and-data","page":"Peak fitting the Raman spectrum of a glass","title":"Importing libraries and data","text":"","category":"section"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"First, we import the libraries for doing various things:","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"# our Spectra library\nusing Spectra\n# to have access to core functions like mean() or std()\nusing Statistics\n# to import the data\nusing DelimitedFiles\n\n# Plotting libraries\nusing Plots\ngr()\n# LaTeX for superscripts/subscripts in labels, captions...\nusing LaTeXStrings","category":"page"},{"location":"examples/Raman_spectrum_fitting.html#Importing-data","page":"Peak fitting the Raman spectrum of a glass","title":"Importing data","text":"","category":"section"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"For that, we use readdlm from DelimitedFiles, and we skip the header and footer lines.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"data = readdlm(joinpath(@__DIR__, \"data/LS4.txt\"), '\\t', Float64)\nskip_header = 23\nskip_footer = 121\ninputsp = zeros(size(data)[1]-skip_header-skip_footer,2)\nj = 1\nfor i = skip_header+1:size(data)[1]-skip_footer\n    inputsp[j,1] = Float64(data[i,1])\n    inputsp[j,2] = Float64(data[i,2])\n    global j += 1\nend","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"We will now make the following pre-processing: we correct the data from temperature and excitation line effects using the tlcorrection function. It is not always necessary at frequencies > 500 cm-1, but this is just for the sack of example in the present case","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"x, y, ese_y = tlcorrection(inputsp, 23.0, 490.0)","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"and now we create a new plot for showing the spectrum","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"plot(x, y,\nxlabel=L\"Raman shift, cm$^{-1}$\",\nylabel=\"Normalized intensity, a. u.\",\ntitle=\"Figure 1: the spectrum of interest\")\nsavefig(\"rsf_1.svg\"); nothing #hide","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"(Image: )","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"So we are looking at the 500-1300 cm^-1 portion of the Raman spectrum of the glass. We see a peak near 800 cm^-1, and two others near 950 and 1085 cm^-1. We will be interested in fitting the 870-1300 cm^-1 portion of this spectrum, which can be assigned to the various symmetric and assymetric stretching vibrations of Si-O bonds in the SiO_2 tetrahedra present in the glass network (see the above cited litterature for details).","category":"page"},{"location":"examples/Raman_spectrum_fitting.html#Baseline-Removal","page":"Peak fitting the Raman spectrum of a glass","title":"Baseline Removal","text":"","category":"section"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"First thing we notice in Fig. 1, we have to remove a baseline because this spectrum is shifted from 0 by some \"background\" scattering. This quite typical in Raman spectra of glasses. Several ways exist to do so. We're going to the simplest thing: a polynomial fitting the signal base around 870 and 1300 cm^-1. Other reasonnable solutions include a linear function, and a constant function. The two latter can be fitted between 1300 and 1350 cm^-1, but we will need to add another peak around 800 cm^-1. For now, the example is done with fitting the 870 cm^-1 portion of spectra, as this usually results in more robust final results.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"First, we define the regions of interest roi where we think the baseline is. Then, we call the baseline function to define the baseline and subtract it from y.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"roi = [860.0 870.0; 1300.0 1400.0]\ny_corr, y_bas = baseline(x, y, roi=roi, method=\"polynomial\", polynomial_order=2)\n\n# To visualize this, we create a plot showing the baseline:\nplot(x, [y y_corr y_bas],\nxlabel=L\"Raman shift, cm$^{-1}$\",\nylabel=\"Normalized intensity, a. u.\",\ntitle=\"Figure 2: the fit of the background\")\nsavefig(\"rsf_2.svg\"); nothing #hide","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"(Image: )","category":"page"},{"location":"examples/Raman_spectrum_fitting.html#Signal-extraction-and-normalisation","page":"Peak fitting the Raman spectrum of a glass","title":"Signal extraction and normalisation","text":"","category":"section"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Now we will get the portion of the spectrum we want to fit using extract_signal. Then we normalise the signal using normalise. We will calculate the errors based on the comparison between the signal and its \"smoothed version\", provided by smooth.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"# First we extract the signal we want to fit:\nx_fit, y_fit, _ = extract_signal(x, y_corr, [860. 1300.])\n\n# We normalise y_fit so that its area is 1\ny_fit = normalise(y_fit; x=x_fit, method=\"area\")\n\n# We smoothed the signal and get an estimate of the errors using it.\ny_fit_perfect = smooth(x_fit, y_fit, method=\"whittaker\", lambda=1e2)\nese_y_fit = sqrt.(mean((y_fit_perfect-y_fit).^2)) * ones(size(y_fit_perfect))\n\n# Let's have a look at the signal in the fitting region\nplot(x_fit, y_fit, label=\"Signal to fit\")\nplot!(x_fit, y_fit_perfect, label=\"smoothed\",\n    xlabel=L\"Raman shift, cm$^{-1}$\",\n    ylabel=\"Normalized intensity, a. u.\",\n    title=\"Figure 3: signal to peak fit\")\nsavefig(\"rsf_3.svg\"); nothing #hide","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"(Image: )","category":"page"},{"location":"examples/Raman_spectrum_fitting.html#Fitting-the-spectrum","page":"Peak fitting the Raman spectrum of a glass","title":"Fitting the spectrum","text":"","category":"section"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"We do the fit using the fit_peaks function with the quasi-Newton algorithm. From the litterature, we have five peaks (see Le Losq et al. 2014, 2015 and references therein). Compared to earlier studies, we also now know that the main one near 1080 cm^-1 may be actually a pseudovoigt peak.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Here we will place a strong prior on the intensity of the peak near 1090 cm^-1. It seems even a bit unrealistic but the influence of the prior loss compared to the data loss is somehow small, so if you want to add tight constraints you sometime need to place low uncertainties on the prior values of the parameters you want to constrain. Here we assume that the central band should be fit by a peak with a strong intensity. We use a 1 \\% prior uncertainty on a prior value that actually is 10 \\% lower than the maximum intensity:","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"max_y = maximum(y_fit)\nprior_main_peak = max_y-0.1*max_y\nprior_main_peak_uncertainty = 0.01*prior_main_peak","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Let's implement that in a peaks_info vector of peak parameters, uncertainties and boundaries.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Then we declare the context and have a look at the prior mode. If necessary we re-adjust it. Keep in mind that it should be fairly close to the solution, as the algorithms (here the quasi-Newton method) we use are local search algorithms.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"The peaks_info vector is a list of tuples, each tuple containing the following information:","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"the type of peak (e.g. :gaussian, :lorentzian, :pseudovoigt)\nthe parameters of the peak (e.g. amplitude, position, width, shape)\nthe uncertainties on the parameters (e.g. amplitude, position, width, shape)\nthe lower bounds for the parameters (e.g. amplitude, position, width, shape)\nthe upper bounds for the parameters (e.g. amplitude, position, width, shape)","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"peaks_info = [\n        (:gaussian,    [0.002, 950, 27],       [0.0005, 5.0,3.0], [0.0, 0.0, 0.0], [Inf, Inf, 60.0]),\n        (:gaussian,    [0.0044, 1044, 40],      [0.0005, 5.0, 3.0], [0.0, 0.0, 0.0], [Inf, Inf, 60.0]),\n        (:pseudovoigt,   [prior_main_peak, 1086, 30., 0.8], [prior_main_peak_uncertainty, 5.0, 3.0, 0.02], [0.0, 0.0, 0.0, 0.0], [Inf, Inf, 60.0, 1.0]),\n        (:gaussian,    [0.0028, 1150, 45],      [0.0005, 5.0, 3.0], [0.0, 0.0, 0.0], [Inf, Inf, 60.0]),\n        (:gaussian,    [0.0009, 1185, 30],      [0.0001, 5.0, 3.0], [0.0, 0.0, 0.0], [Inf, Inf, 60.0]),\n    ]\n\n# we declare the context of the fit\nctx = prepare_context(x_fit, y_fit, peaks_info, ese_y_fit)\n\n# We plot the prior model\np = plot_fit(ctx, title=\"Prior model\")\nsavefig(\"rsf_4.svg\"); nothing #hide","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"(Image: )","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"# doing the fit\nresult = fit_peaks(ctx, backend=:Optim, relax=5, maxiter=100)\n\n# we print the result using\nprint_params(result.peak_results)\n\n# and we plot the fit\nplot_fit(ctx, result.peak_results)\nsavefig(\"rsf_5.svg\"); nothing #hide","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"(Image: )","category":"page"},{"location":"examples/Raman_spectrum_fitting.html#Checking-errors-with-bootstrapping","page":"Peak fitting the Raman spectrum of a glass","title":"Checking errors with bootstrapping","text":"","category":"section"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"The error bars above appear fairly small... We check them using boostrapping. Again, we use a unrealistically low number of bootstrapped samples here because this code runs during documentation generation, but in reality you would like to increase nb_boot to something like 1000. I also fidled with maxiter to set it to a small value while still seeing convergence, such that we don't spend too much time in the quasi-Newton algorithm.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"boot_samples, boot_results = bootstrap(x_fit, y_fit, ese_y_fit, peaks_info, nb_boot = 50, backend=:qGN, relax=5., maxiter=20)","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"We can now print the bootstrapped results and compare the errors with those previously calculated from the Hessian:","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"print_params(boot_results)","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"OK, actually for this example, we see that the errors from the boostrap analysis are close to those calculated from the Hessian matrix. Everything thus seems OK.","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"Of course, a final quick visual inspection is always nice. This can be done by passing boot_results to the plot_fit function","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"plot_fit(ctx, boot_results)\nsavefig(\"rsf_6.svg\"); nothing #hide","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"(Image: )","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"","category":"page"},{"location":"examples/Raman_spectrum_fitting.html","page":"Peak fitting the Raman spectrum of a glass","title":"Peak fitting the Raman spectrum of a glass","text":"This page was generated using Literate.jl.","category":"page"},{"location":"index.html#Welcome-to-Spectra's-documentation!","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"","category":"section"},{"location":"index.html#Introduction","page":"Welcome to Spectra's documentation!","title":"Introduction","text":"","category":"section"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Spectra.jl is a Julia package designed to simplify the treatment of spectroscopic data (Raman, Infrared, Nuclear Magnetic Resonance, XAS, etc.). It provides straightforward tools for common tasks such as smoothing, baseline fitting, and peak fitting, while preserving the flexibility and power of programmatic data analysis in Julia. Spectra.jl is particularly suited for large datasets and integrates well with other Julia packages, such as JuMP for model building.","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Please consult this documentation to learn how to use Spectra.jl. Check the Tips section if you encounter issues, and feel free to report problems or suggest improvements!","category":"page"},{"location":"index.html#Starting-Notes","page":"Welcome to Spectra's documentation!","title":"Starting Notes","text":"","category":"section"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Reading the docs is strongly recommended! \nIf you are new to Julia, start by reading the official documentation of Julia.\nYou can develop your code in text editors such as Visual Studio Code, or use interactive environments such as IJulia Jupyter notebooks or the reactive Pluto notebooks.","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"important: Important\nSpectra v2.0.0 API has evolved a lot since v1.0.0. There are breaking changes that may require to update your codes.","category":"page"},{"location":"index.html#Installation","page":"Welcome to Spectra's documentation!","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Cloud (JuliaHub):","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Launch a notebook on JuliaHub.\nIn your first cell, run:  using Pkg  Pkg.add(\"Spectra\")","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Local:","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Download Julia from the official website.\nOpen the Julia REPL, press ] to enter package mode (Pkg>), then run:  Pkg> add Spectra","category":"page"},{"location":"index.html#Getting-help","page":"Welcome to Spectra's documentation!","title":"Getting help","text":"","category":"section"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"The search bar on the top left of this website is useful to search the documentation, or also you can use the function index at the end of this page for instance.\nYou can also use the help mode in Julia's REPL by typing ? in the REPL, then the function name:","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"julia> ?\nhelp?> function_you_want_to_know_about","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"If you encounter issues or have suggestions, open an issue on GitHub with details about your setup and steps to reproduce any errors.","category":"page"},{"location":"index.html#Contributing","page":"Welcome to Spectra's documentation!","title":"Contributing","text":"","category":"section"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"Contributions are welcome! You can fork the project, submit pull requests, or open issues for bugs and feature requests. The feature set is not exhaustive, and community help is appreciated.","category":"page"},{"location":"index.html#Citing-Spectra","page":"Welcome to Spectra's documentation!","title":"Citing Spectra","text":"","category":"section"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"If you use Spectra.jl in your work, please cite:","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"LE LOSQ, C. (2016) Spectra: a Julia package for processing spectroscopic data. Zenodo. 10.5281/zenodo.53940","category":"page"},{"location":"index.html#Index","page":"Welcome to Spectra's documentation!","title":"Index","text":"","category":"section"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"The functions available in Spectra.jl are listed below. See the rest of the documentation for detailed usage.","category":"page"},{"location":"index.html","page":"Welcome to Spectra's documentation!","title":"Welcome to Spectra's documentation!","text":"","category":"page"}]
}
